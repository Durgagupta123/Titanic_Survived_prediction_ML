{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2caa006",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0234dafc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To load the dataset\n",
    "df = pd.read_csv(\"titanic.csv\")\n",
    "\n",
    "#to show first 5 records\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a10de9dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Total number of rows and columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc98a2cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To check null value\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "960e1fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualization of missing data\n",
    "sb.heatmap(df.isnull())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8e52baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the cabin column as more than 50% data null, so will delete the column instead of replacing the\n",
    "#values in column\n",
    "df.drop('Cabin',axis=1,inplace=True)  #inplace=True for permanent change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9d69427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#now age column as approximate 20% data null so we replace the null value\n",
    "#to check pclass with age by using box plot\n",
    "plt.figure(figsize=(15,10))\n",
    "sb.set_style('whitegrid')\n",
    "sb.boxplot(data=df,x=\"Pclass\",y=\"Age\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed0d6060",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from above box plot we get that around age 37 the pclass=1,\n",
    "#around age 29 the pclass=2 and around age=24 the pclass=3\n",
    "#we use this average age value to impute based on pclass for age\n",
    "def impute_age(cols):\n",
    "    Age = cols[0]\n",
    "    Pclass = cols[1]\n",
    "    \n",
    "    if pd.isnull(Age): \n",
    "        if Pclass==1:\n",
    "            return 37\n",
    "        elif Pclass==2:\n",
    "            return 29\n",
    "        else:\n",
    "            return 24\n",
    "    else:\n",
    "        return Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0014685",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now call the function\n",
    "df[\"Age\"] = df[[\"Age\",\"Pclass\"]].apply(impute_age,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df8eea01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0\n",
       "Survived       0\n",
       "Pclass         0\n",
       "Name           0\n",
       "Sex            0\n",
       "Age            0\n",
       "SibSp          0\n",
       "Parch          0\n",
       "Ticket         0\n",
       "Fare           0\n",
       "Embarked       2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now check the null value \n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35ca2d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Embarked as only 2 null value so we delete that rows\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25e21324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0\n",
       "Survived       0\n",
       "Pclass         0\n",
       "Name           0\n",
       "Sex            0\n",
       "Age            0\n",
       "SibSp          0\n",
       "Parch          0\n",
       "Ticket         0\n",
       "Fare           0\n",
       "Embarked       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now check the null value again\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00a65b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      int64\n",
       "Survived         int64\n",
       "Pclass           int64\n",
       "Name            object\n",
       "Sex             object\n",
       "Age            float64\n",
       "SibSp            int64\n",
       "Parch            int64\n",
       "Ticket          object\n",
       "Fare           float64\n",
       "Embarked        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cross check the null value by data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7b8e29a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To check the duplicated values\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb7d5b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Machine always accept the numerical datatypes(int/float) \n",
    "#which means machine will not take categorical datatypes\n",
    "#To convert categorical datatype to numerical datatype we use LabelEncoder\n",
    "#call inbuilt class \n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ce46e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an object by spliting the datatypes\n",
    "df_num = df.select_dtypes([\"int64\",\"float64\"])  #hold all columns with int and float\n",
    "df_cat = df.select_dtypes(object)   #hold object type columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5df654fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass   Age  SibSp  Parch     Fare\n",
       "0            1         0       3  22.0      1      0   7.2500\n",
       "1            2         1       1  38.0      1      0  71.2833\n",
       "2            3         1       3  26.0      0      0   7.9250\n",
       "3            4         1       1  35.0      1      0  53.1000\n",
       "4            5         0       3  35.0      0      0   8.0500"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0968ef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>113803</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>373450</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Name     Sex  \\\n",
       "0                            Braund, Mr. Owen Harris    male   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female   \n",
       "2                             Heikkinen, Miss. Laina  female   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female   \n",
       "4                           Allen, Mr. William Henry    male   \n",
       "\n",
       "             Ticket Embarked  \n",
       "0         A/5 21171        S  \n",
       "1          PC 17599        C  \n",
       "2  STON/O2. 3101282        S  \n",
       "3            113803        S  \n",
       "4            373450        S  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24c703b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply LabelEncoder to df_cat to convert object datatype to numerical datatype\n",
    "#create an object for LabelEncoder class\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "814288b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#by using for loop\n",
    "for col in df_cat:\n",
    "    df_cat[col] = le.fit_transform(df_cat[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14946e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name        int32\n",
       "Sex         int32\n",
       "Ticket      int32\n",
       "Embarked    int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to check \n",
    "df_cat.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3fc058f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>522</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>190</td>\n",
       "      <td>0</td>\n",
       "      <td>595</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>353</td>\n",
       "      <td>0</td>\n",
       "      <td>668</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>471</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass   Age  SibSp  Parch     Fare  Name  Sex  \\\n",
       "0            1         0       3  22.0      1      0   7.2500   108    1   \n",
       "1            2         1       1  38.0      1      0  71.2833   190    0   \n",
       "2            3         1       3  26.0      0      0   7.9250   353    0   \n",
       "3            4         1       1  35.0      1      0  53.1000   272    0   \n",
       "4            5         0       3  35.0      0      0   8.0500    15    1   \n",
       "\n",
       "   Ticket  Embarked  \n",
       "0     522         2  \n",
       "1     595         0  \n",
       "2     668         2  \n",
       "3      48         2  \n",
       "4     471         2  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now merge/joint the both datatype (df_num,df_cat)\n",
    "df = pd.concat([df_num,df_cat],axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd763772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      int64\n",
       "Survived         int64\n",
       "Pclass           int64\n",
       "Age            float64\n",
       "SibSp            int64\n",
       "Parch            int64\n",
       "Fare           float64\n",
       "Name             int32\n",
       "Sex              int32\n",
       "Ticket           int32\n",
       "Embarked         int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5ace4ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have calssification dataset which means we solve this with classification algorithm\n",
    "#1. use Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f8f18c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    549\n",
       "1    340\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How many categories in output variable\n",
    "f = df[\"Survived\"].value_counts()\n",
    "sb.countplot(data=df,x=\"Survived\")\n",
    "plt.yticks(f)\n",
    "plt.show()\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "115e6493",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select input and output\n",
    "x = df.drop(\"Survived\",axis=1)   #input \n",
    "y = df[\"Survived\"]               #output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c175ab93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>522</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>190</td>\n",
       "      <td>0</td>\n",
       "      <td>595</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>353</td>\n",
       "      <td>0</td>\n",
       "      <td>668</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>471</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass   Age  SibSp  Parch     Fare  Name  Sex  Ticket  \\\n",
       "0            1       3  22.0      1      0   7.2500   108    1     522   \n",
       "1            2       1  38.0      1      0  71.2833   190    0     595   \n",
       "2            3       3  26.0      0      0   7.9250   353    0     668   \n",
       "3            4       1  35.0      1      0  53.1000   272    0      48   \n",
       "4            5       3  35.0      0      0   8.0500    15    1     471   \n",
       "\n",
       "   Embarked  \n",
       "0         2  \n",
       "1         0  \n",
       "2         2  \n",
       "3         2  \n",
       "4         2  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "47739773",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now Split the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "50d67310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((622, 10), (267, 10))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape , x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9bcf50fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying StandardScaler on x_train and x_test\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#create an object for StandardScaler class\n",
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ca08f469",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model\n",
    "x_train = ss.fit_transform(x_train)\n",
    "x_test = ss.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4ff94a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function\n",
    "def create_model(model):\n",
    "    model.fit(x_train,y_train)    #train the model with 70% data\n",
    "    y_pred = model.predict(x_test) #test the model with 30% data\n",
    "    \n",
    "    #generate Report\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4ca4fa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#call the class \n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0091a65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform the base model that is Linaer Regression\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4d117f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an object for LinearRegression class\n",
    "lr = LogisticRegression(random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f977e700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87       166\n",
      "           1       0.78      0.79      0.79       101\n",
      "\n",
      "    accuracy                           0.84       267\n",
      "   macro avg       0.83      0.83      0.83       267\n",
      "weighted avg       0.84      0.84      0.84       267\n",
      "\n",
      "[[144  22]\n",
      " [ 21  80]]\n"
     ]
    }
   ],
   "source": [
    "#call function\n",
    "lr = create_model(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0014e096",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we get recall value 79% which is good but not better\n",
    "#So we move to next classification that is Decision Tree Classifier\n",
    "#Now let's perform DecisionTreeClassifier with GINI Index\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6a190e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.83      0.83       166\n",
      "           1       0.73      0.73      0.73       101\n",
      "\n",
      "    accuracy                           0.79       267\n",
      "   macro avg       0.78      0.78      0.78       267\n",
      "weighted avg       0.79      0.79      0.79       267\n",
      "\n",
      "[[138  28]\n",
      " [ 27  74]]\n"
     ]
    }
   ],
   "source": [
    "#Create an object for DecisionTreeClassifier class\n",
    "dtc = DecisionTreeClassifier(random_state=1)   #by default its takes GINI Index\n",
    "\n",
    "#call the function\n",
    "dtc = create_model(dtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1e55a644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>IG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sex</td>\n",
       "      <td>0.260133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ticket</td>\n",
       "      <td>0.154264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fare</td>\n",
       "      <td>0.123060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PassengerId</td>\n",
       "      <td>0.117978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Name</td>\n",
       "      <td>0.111308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.097998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pclass</td>\n",
       "      <td>0.076617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SibSp</td>\n",
       "      <td>0.033296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Parch</td>\n",
       "      <td>0.018233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Embarked</td>\n",
       "      <td>0.007114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Input        IG\n",
       "0          Sex  0.260133\n",
       "1       Ticket  0.154264\n",
       "2         Fare  0.123060\n",
       "3  PassengerId  0.117978\n",
       "4         Name  0.111308\n",
       "5          Age  0.097998\n",
       "6       Pclass  0.076617\n",
       "7        SibSp  0.033296\n",
       "8        Parch  0.018233\n",
       "9     Embarked  0.007114"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now check information gain(IG)\n",
    "dict1 = {\"Input\":x.columns,\"IG\":dtc.feature_importances_}\n",
    "df2 = pd.DataFrame(dict1)\n",
    "df2.sort_values(\"IG\",ascending=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e95c93a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To create the tree , call tree outer class from sklearn package\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f6e50b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = x.columns\n",
    "plt.figure(figsize=(20,20))\n",
    "#_=tree.plot_tree(dtc,feature_names=f,filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0b01104b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#By GINI Index we get recall score 73% , which means the model is overfit\n",
    "#So we use Pruning technique for overfittin situation\n",
    "#Pruning as 2 types 1.max_depth and 2. min_samples_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5a2ddaf3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Depth: 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86       166\n",
      "           1       0.77      0.74      0.76       101\n",
      "\n",
      "    accuracy                           0.82       267\n",
      "   macro avg       0.81      0.81      0.81       267\n",
      "weighted avg       0.82      0.82      0.82       267\n",
      "\n",
      "[[144  22]\n",
      " [ 26  75]]\n",
      "Max Depth: 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.93      0.84       166\n",
      "           1       0.83      0.54      0.66       101\n",
      "\n",
      "    accuracy                           0.79       267\n",
      "   macro avg       0.80      0.74      0.75       267\n",
      "weighted avg       0.79      0.79      0.77       267\n",
      "\n",
      "[[155  11]\n",
      " [ 46  55]]\n",
      "Max Depth: 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.94      0.87       166\n",
      "           1       0.86      0.63      0.73       101\n",
      "\n",
      "    accuracy                           0.82       267\n",
      "   macro avg       0.84      0.79      0.80       267\n",
      "weighted avg       0.83      0.82      0.82       267\n",
      "\n",
      "[[156  10]\n",
      " [ 37  64]]\n",
      "Max Depth: 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.87      0.85       166\n",
      "           1       0.77      0.70      0.74       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.80      0.79      0.79       267\n",
      "weighted avg       0.81      0.81      0.81       267\n",
      "\n",
      "[[145  21]\n",
      " [ 30  71]]\n",
      "Max Depth: 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.84      0.86       166\n",
      "           1       0.76      0.83      0.79       101\n",
      "\n",
      "    accuracy                           0.84       267\n",
      "   macro avg       0.82      0.83      0.83       267\n",
      "weighted avg       0.84      0.84      0.84       267\n",
      "\n",
      "[[139  27]\n",
      " [ 17  84]]\n",
      "Max Depth: 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86       166\n",
      "           1       0.78      0.72      0.75       101\n",
      "\n",
      "    accuracy                           0.82       267\n",
      "   macro avg       0.81      0.80      0.81       267\n",
      "weighted avg       0.82      0.82      0.82       267\n",
      "\n",
      "[[146  20]\n",
      " [ 28  73]]\n",
      "Max Depth: 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.87      0.84       166\n",
      "           1       0.76      0.69      0.73       101\n",
      "\n",
      "    accuracy                           0.80       267\n",
      "   macro avg       0.79      0.78      0.78       267\n",
      "weighted avg       0.80      0.80      0.80       267\n",
      "\n",
      "[[144  22]\n",
      " [ 31  70]]\n",
      "Max Depth: 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.85       166\n",
      "           1       0.76      0.71      0.73       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.79      0.79      0.79       267\n",
      "weighted avg       0.80      0.81      0.80       267\n",
      "\n",
      "[[143  23]\n",
      " [ 29  72]]\n"
     ]
    }
   ],
   "source": [
    "#1.Max Depth : apply on DecisionTreeClassifier class with range between >=1 and <=8\n",
    "for i in range(1,9):\n",
    "    #create object for DecisionTreeClassifier class\n",
    "    dtc1 = DecisionTreeClassifier(random_state=1,max_depth=i)\n",
    "    print(\"Max Depth:\",i)\n",
    "    #call function\n",
    "    dtc1 = create_model(dtc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "704c1100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.84      0.86       166\n",
      "           1       0.76      0.83      0.79       101\n",
      "\n",
      "    accuracy                           0.84       267\n",
      "   macro avg       0.82      0.83      0.83       267\n",
      "weighted avg       0.84      0.84      0.84       267\n",
      "\n",
      "[[139  27]\n",
      " [ 17  84]]\n"
     ]
    }
   ],
   "source": [
    "dtc1 = DecisionTreeClassifier(random_state=1,max_depth=5)\n",
    "#call function\n",
    "dtc1 = create_model(dtc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "800982f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>IG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sex</td>\n",
       "      <td>0.438668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ticket</td>\n",
       "      <td>0.187228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pclass</td>\n",
       "      <td>0.129201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.092422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SibSp</td>\n",
       "      <td>0.046790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fare</td>\n",
       "      <td>0.046427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Name</td>\n",
       "      <td>0.045263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PassengerId</td>\n",
       "      <td>0.014001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Parch</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Embarked</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Input        IG\n",
       "0          Sex  0.438668\n",
       "1       Ticket  0.187228\n",
       "2       Pclass  0.129201\n",
       "3          Age  0.092422\n",
       "4        SibSp  0.046790\n",
       "5         Fare  0.046427\n",
       "6         Name  0.045263\n",
       "7  PassengerId  0.014001\n",
       "8        Parch  0.000000\n",
       "9     Embarked  0.000000"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now check information gain(IG)\n",
    "dict2 = {\"Input\":x.columns,\"IG\":dtc1.feature_importances_}\n",
    "df3 = pd.DataFrame(dict2)\n",
    "df3.sort_values(\"IG\",ascending=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "16c7a50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the recall score 0.83(83%) in DecisionTreeClassifier class using max_depth pruning tech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "111d10c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Samples Leaf: 45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88       166\n",
      "           1       0.88      0.66      0.76       101\n",
      "\n",
      "    accuracy                           0.84       267\n",
      "   macro avg       0.85      0.80      0.82       267\n",
      "weighted avg       0.84      0.84      0.83       267\n",
      "\n",
      "[[157   9]\n",
      " [ 34  67]]\n",
      "Min Samples Leaf: 46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88       166\n",
      "           1       0.88      0.66      0.76       101\n",
      "\n",
      "    accuracy                           0.84       267\n",
      "   macro avg       0.85      0.80      0.82       267\n",
      "weighted avg       0.84      0.84      0.83       267\n",
      "\n",
      "[[157   9]\n",
      " [ 34  67]]\n",
      "Min Samples Leaf: 47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88       166\n",
      "           1       0.88      0.66      0.76       101\n",
      "\n",
      "    accuracy                           0.84       267\n",
      "   macro avg       0.85      0.80      0.82       267\n",
      "weighted avg       0.84      0.84      0.83       267\n",
      "\n",
      "[[157   9]\n",
      " [ 34  67]]\n",
      "Min Samples Leaf: 48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88       166\n",
      "           1       0.88      0.66      0.76       101\n",
      "\n",
      "    accuracy                           0.84       267\n",
      "   macro avg       0.85      0.80      0.82       267\n",
      "weighted avg       0.84      0.84      0.83       267\n",
      "\n",
      "[[157   9]\n",
      " [ 34  67]]\n",
      "Min Samples Leaf: 49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.87       166\n",
      "           1       0.88      0.64      0.74       101\n",
      "\n",
      "    accuracy                           0.83       267\n",
      "   macro avg       0.85      0.79      0.81       267\n",
      "weighted avg       0.84      0.83      0.82       267\n",
      "\n",
      "[[157   9]\n",
      " [ 36  65]]\n",
      "Min Samples Leaf: 50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.87       166\n",
      "           1       0.88      0.64      0.74       101\n",
      "\n",
      "    accuracy                           0.83       267\n",
      "   macro avg       0.85      0.79      0.81       267\n",
      "weighted avg       0.84      0.83      0.82       267\n",
      "\n",
      "[[157   9]\n",
      " [ 36  65]]\n",
      "Min Samples Leaf: 51\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 54\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 59\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 63\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 74\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 76\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 91\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 92\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n"
     ]
    }
   ],
   "source": [
    "#2.Min Samples Leaf : apply on DecisionTreeClassifier class with range between >=45 and <=100\n",
    "for i in range(45,101):\n",
    "    #create object for DecisionTreeClassifier class\n",
    "    dtc2 = DecisionTreeClassifier(random_state=1,min_samples_leaf=i)\n",
    "    print(\"Min Samples Leaf:\",i)\n",
    "    #call function\n",
    "    dtc2 = create_model(dtc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fd02ca9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88       166\n",
      "           1       0.88      0.66      0.76       101\n",
      "\n",
      "    accuracy                           0.84       267\n",
      "   macro avg       0.85      0.80      0.82       267\n",
      "weighted avg       0.84      0.84      0.83       267\n",
      "\n",
      "[[157   9]\n",
      " [ 34  67]]\n"
     ]
    }
   ],
   "source": [
    "dtc2 = DecisionTreeClassifier(random_state=1,min_samples_leaf=45)\n",
    "#call function\n",
    "dtc2 = create_model(dtc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f4b876c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>IG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sex</td>\n",
       "      <td>0.641111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pclass</td>\n",
       "      <td>0.188827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fare</td>\n",
       "      <td>0.091865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ticket</td>\n",
       "      <td>0.072409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PassengerId</td>\n",
       "      <td>0.005788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SibSp</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Parch</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Name</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Embarked</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Input        IG\n",
       "0          Sex  0.641111\n",
       "1       Pclass  0.188827\n",
       "2         Fare  0.091865\n",
       "3       Ticket  0.072409\n",
       "4  PassengerId  0.005788\n",
       "5          Age  0.000000\n",
       "6        SibSp  0.000000\n",
       "7        Parch  0.000000\n",
       "8         Name  0.000000\n",
       "9     Embarked  0.000000"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now check information gain(IG)\n",
    "dict3 = {\"Input\":x.columns,\"IG\":dtc2.feature_importances_}\n",
    "df4 = pd.DataFrame(dict3)\n",
    "df4.sort_values(\"IG\",ascending=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "992354d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# while applying pruning tech on DecisionTreeClassifier we got recall score 0.66(66%) \n",
    "#which is not good so we apply next algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ec2a8d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.75      0.79       166\n",
      "           1       0.65      0.74      0.69       101\n",
      "\n",
      "    accuracy                           0.75       267\n",
      "   macro avg       0.74      0.75      0.74       267\n",
      "weighted avg       0.76      0.75      0.75       267\n",
      "\n",
      "[[125  41]\n",
      " [ 26  75]]\n"
     ]
    }
   ],
   "source": [
    "#3.DecisionTreeClassifier with Entropy Index :\n",
    "dtc_entropy = DecisionTreeClassifier(random_state=1,criterion='entropy')\n",
    "#call function\n",
    "dtc_entropy = create_model(dtc_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7c44d9e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>IG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sex</td>\n",
       "      <td>0.198204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PassengerId</td>\n",
       "      <td>0.147369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ticket</td>\n",
       "      <td>0.147166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fare</td>\n",
       "      <td>0.141706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.119131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Name</td>\n",
       "      <td>0.100858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pclass</td>\n",
       "      <td>0.077257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SibSp</td>\n",
       "      <td>0.045962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Embarked</td>\n",
       "      <td>0.013128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Parch</td>\n",
       "      <td>0.009218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Input        IG\n",
       "0          Sex  0.198204\n",
       "1  PassengerId  0.147369\n",
       "2       Ticket  0.147166\n",
       "3         Fare  0.141706\n",
       "4          Age  0.119131\n",
       "5         Name  0.100858\n",
       "6       Pclass  0.077257\n",
       "7        SibSp  0.045962\n",
       "8     Embarked  0.013128\n",
       "9        Parch  0.009218"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now check information gain(IG)\n",
    "dict4 = {\"Input\":x.columns,\"IG\":dtc_entropy.feature_importances_}\n",
    "df5 = pd.DataFrame(dict4)\n",
    "df5.sort_values(\"IG\",ascending=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "277f4a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2160x2160 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualize a tree\n",
    "f = x.columns\n",
    "plt.figure(figsize=(30,30))\n",
    "#_ = tree.plot_tree(dtc_entropy,feature_names=f,filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c75e4dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#By Entropy Index we get recall score 74 , which means the model is overfit\n",
    "#So we use Pruning technique for overfittin situation\n",
    "#Pruning as 2 types 1.max_depth and 2. min_samples_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d7cdcd5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Depth: 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86       166\n",
      "           1       0.77      0.74      0.76       101\n",
      "\n",
      "    accuracy                           0.82       267\n",
      "   macro avg       0.81      0.81      0.81       267\n",
      "weighted avg       0.82      0.82      0.82       267\n",
      "\n",
      "[[144  22]\n",
      " [ 26  75]]\n",
      "Max Depth: 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.93      0.84       166\n",
      "           1       0.83      0.54      0.66       101\n",
      "\n",
      "    accuracy                           0.79       267\n",
      "   macro avg       0.80      0.74      0.75       267\n",
      "weighted avg       0.79      0.79      0.77       267\n",
      "\n",
      "[[155  11]\n",
      " [ 46  55]]\n",
      "Max Depth: 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.89       166\n",
      "           1       0.84      0.76      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[151  15]\n",
      " [ 24  77]]\n",
      "Max Depth: 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.93      0.86       166\n",
      "           1       0.84      0.63      0.72       101\n",
      "\n",
      "    accuracy                           0.82       267\n",
      "   macro avg       0.82      0.78      0.79       267\n",
      "weighted avg       0.82      0.82      0.81       267\n",
      "\n",
      "[[154  12]\n",
      " [ 37  64]]\n",
      "Max Depth: 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83       166\n",
      "           1       0.72      0.70      0.71       101\n",
      "\n",
      "    accuracy                           0.79       267\n",
      "   macro avg       0.77      0.77      0.77       267\n",
      "weighted avg       0.79      0.79      0.79       267\n",
      "\n",
      "[[139  27]\n",
      " [ 30  71]]\n",
      "Max Depth: 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.85       166\n",
      "           1       0.75      0.81      0.78       101\n",
      "\n",
      "    accuracy                           0.82       267\n",
      "   macro avg       0.81      0.82      0.82       267\n",
      "weighted avg       0.83      0.82      0.83       267\n",
      "\n",
      "[[138  28]\n",
      " [ 19  82]]\n",
      "Max Depth: 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81       166\n",
      "           1       0.69      0.71      0.70       101\n",
      "\n",
      "    accuracy                           0.77       267\n",
      "   macro avg       0.76      0.76      0.76       267\n",
      "weighted avg       0.77      0.77      0.77       267\n",
      "\n",
      "[[134  32]\n",
      " [ 29  72]]\n",
      "Max Depth: 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82       166\n",
      "           1       0.71      0.69      0.70       101\n",
      "\n",
      "    accuracy                           0.78       267\n",
      "   macro avg       0.76      0.76      0.76       267\n",
      "weighted avg       0.77      0.78      0.77       267\n",
      "\n",
      "[[137  29]\n",
      " [ 31  70]]\n"
     ]
    }
   ],
   "source": [
    "#1.Max Depth : apply on DecisionTreeClassifier class with range between >=1 and <=8\n",
    "for i in range(1,9):\n",
    "    #create object for DecisionTreeClassifier class with entropy index\n",
    "    dtc_entropy_1 = DecisionTreeClassifier(random_state=1,criterion='entropy',max_depth=i)\n",
    "    print(\"Max Depth:\",i)\n",
    "    #call function\n",
    "    dtc_entropy_1 = create_model(dtc_entropy_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ba32f496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.85       166\n",
      "           1       0.75      0.81      0.78       101\n",
      "\n",
      "    accuracy                           0.82       267\n",
      "   macro avg       0.81      0.82      0.82       267\n",
      "weighted avg       0.83      0.82      0.83       267\n",
      "\n",
      "[[138  28]\n",
      " [ 19  82]]\n"
     ]
    }
   ],
   "source": [
    "dtc_entropy_1 = DecisionTreeClassifier(random_state=1,criterion='entropy',max_depth=6)\n",
    "#call function\n",
    "dtc_entropy_1 = create_model(dtc_entropy_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f0d42393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>IG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sex</td>\n",
       "      <td>0.329047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fare</td>\n",
       "      <td>0.161379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ticket</td>\n",
       "      <td>0.137124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pclass</td>\n",
       "      <td>0.123111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.088399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Name</td>\n",
       "      <td>0.066397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PassengerId</td>\n",
       "      <td>0.048570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SibSp</td>\n",
       "      <td>0.045972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Parch</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Embarked</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Input        IG\n",
       "0          Sex  0.329047\n",
       "1         Fare  0.161379\n",
       "2       Ticket  0.137124\n",
       "3       Pclass  0.123111\n",
       "4          Age  0.088399\n",
       "5         Name  0.066397\n",
       "6  PassengerId  0.048570\n",
       "7        SibSp  0.045972\n",
       "8        Parch  0.000000\n",
       "9     Embarked  0.000000"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now check information gain(IG)\n",
    "dict5 = {\"Input\":x.columns,\"IG\":dtc_entropy_1.feature_importances_}\n",
    "df6 = pd.DataFrame(dict5)\n",
    "df6.sort_values(\"IG\",ascending=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2495cc9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Samples Leaf: 45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88       166\n",
      "           1       0.88      0.66      0.76       101\n",
      "\n",
      "    accuracy                           0.84       267\n",
      "   macro avg       0.85      0.80      0.82       267\n",
      "weighted avg       0.84      0.84      0.83       267\n",
      "\n",
      "[[157   9]\n",
      " [ 34  67]]\n",
      "Min Samples Leaf: 46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88       166\n",
      "           1       0.88      0.66      0.76       101\n",
      "\n",
      "    accuracy                           0.84       267\n",
      "   macro avg       0.85      0.80      0.82       267\n",
      "weighted avg       0.84      0.84      0.83       267\n",
      "\n",
      "[[157   9]\n",
      " [ 34  67]]\n",
      "Min Samples Leaf: 47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88       166\n",
      "           1       0.88      0.66      0.76       101\n",
      "\n",
      "    accuracy                           0.84       267\n",
      "   macro avg       0.85      0.80      0.82       267\n",
      "weighted avg       0.84      0.84      0.83       267\n",
      "\n",
      "[[157   9]\n",
      " [ 34  67]]\n",
      "Min Samples Leaf: 48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88       166\n",
      "           1       0.88      0.66      0.76       101\n",
      "\n",
      "    accuracy                           0.84       267\n",
      "   macro avg       0.85      0.80      0.82       267\n",
      "weighted avg       0.84      0.84      0.83       267\n",
      "\n",
      "[[157   9]\n",
      " [ 34  67]]\n",
      "Min Samples Leaf: 49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.87       166\n",
      "           1       0.88      0.64      0.74       101\n",
      "\n",
      "    accuracy                           0.83       267\n",
      "   macro avg       0.85      0.79      0.81       267\n",
      "weighted avg       0.84      0.83      0.82       267\n",
      "\n",
      "[[157   9]\n",
      " [ 36  65]]\n",
      "Min Samples Leaf: 50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.87       166\n",
      "           1       0.88      0.64      0.74       101\n",
      "\n",
      "    accuracy                           0.83       267\n",
      "   macro avg       0.85      0.79      0.81       267\n",
      "weighted avg       0.84      0.83      0.82       267\n",
      "\n",
      "[[157   9]\n",
      " [ 36  65]]\n",
      "Min Samples Leaf: 51\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 54\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 59\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 63\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 76\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 91\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 92\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n",
      "[[164   2]\n",
      " [ 50  51]]\n",
      "Min Samples Leaf: 100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.86       166\n",
      "           1       0.96      0.50      0.66       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.86      0.75      0.76       267\n",
      "weighted avg       0.84      0.81      0.79       267\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[164   2]\n",
      " [ 50  51]]\n"
     ]
    }
   ],
   "source": [
    "#2.Min Samples Leaf : apply on DecisionTreeClassifier class with range between >=45 and <=100\n",
    "for i in range(45,101):\n",
    "    #create object for DecisionTreeClassifier class\n",
    "    dtc_entropy_2 = DecisionTreeClassifier(random_state=1,criterion='entropy',min_samples_leaf=i)\n",
    "    print(\"Min Samples Leaf:\",i)\n",
    "    #call function\n",
    "    dtc_entropy_2 = create_model(dtc_entropy_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b7745dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88       166\n",
      "           1       0.88      0.66      0.76       101\n",
      "\n",
      "    accuracy                           0.84       267\n",
      "   macro avg       0.85      0.80      0.82       267\n",
      "weighted avg       0.84      0.84      0.83       267\n",
      "\n",
      "[[157   9]\n",
      " [ 34  67]]\n"
     ]
    }
   ],
   "source": [
    "dtc_entropy_2 = DecisionTreeClassifier(random_state=1,criterion='entropy',min_samples_leaf=45)\n",
    "#call function\n",
    "dtc_entropy_2 = create_model(dtc_entropy_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0cddc126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>IG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sex</td>\n",
       "      <td>0.571637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pclass</td>\n",
       "      <td>0.213876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fare</td>\n",
       "      <td>0.113107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ticket</td>\n",
       "      <td>0.083587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Name</td>\n",
       "      <td>0.009827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PassengerId</td>\n",
       "      <td>0.007966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SibSp</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Parch</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Embarked</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Input        IG\n",
       "0          Sex  0.571637\n",
       "1       Pclass  0.213876\n",
       "2         Fare  0.113107\n",
       "3       Ticket  0.083587\n",
       "4         Name  0.009827\n",
       "5  PassengerId  0.007966\n",
       "6          Age  0.000000\n",
       "7        SibSp  0.000000\n",
       "8        Parch  0.000000\n",
       "9     Embarked  0.000000"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now check information gain(IG)\n",
    "dict6 = {\"Input\":x.columns,\"IG\":dtc_entropy_2.feature_importances_}\n",
    "df7 = pd.DataFrame(dict6)\n",
    "df7.sort_values(\"IG\",ascending=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bc622a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We apply 3rd algorithm Random Forest Classifier for furture beeter score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "72ff829b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Estimators: 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.90      0.86       166\n",
      "           1       0.80      0.69      0.74       101\n",
      "\n",
      "    accuracy                           0.82       267\n",
      "   macro avg       0.82      0.80      0.80       267\n",
      "weighted avg       0.82      0.82      0.82       267\n",
      "\n",
      "[[149  17]\n",
      " [ 31  70]]\n",
      "No. of Estimators: 11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87       166\n",
      "           1       0.80      0.75      0.78       101\n",
      "\n",
      "    accuracy                           0.84       267\n",
      "   macro avg       0.83      0.82      0.82       267\n",
      "weighted avg       0.83      0.84      0.83       267\n",
      "\n",
      "[[147  19]\n",
      " [ 25  76]]\n",
      "No. of Estimators: 12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88       166\n",
      "           1       0.83      0.74      0.79       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.84      0.83      0.83       267\n",
      "weighted avg       0.85      0.85      0.84       267\n",
      "\n",
      "[[151  15]\n",
      " [ 26  75]]\n",
      "No. of Estimators: 13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88       166\n",
      "           1       0.83      0.76      0.79       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.83      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[150  16]\n",
      " [ 24  77]]\n",
      "No. of Estimators: 14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90       166\n",
      "           1       0.87      0.76      0.81       101\n",
      "\n",
      "    accuracy                           0.87       267\n",
      "   macro avg       0.87      0.85      0.85       267\n",
      "weighted avg       0.87      0.87      0.86       267\n",
      "\n",
      "[[154  12]\n",
      " [ 24  77]]\n",
      "No. of Estimators: 15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88       166\n",
      "           1       0.81      0.77      0.79       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.84      0.83      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 23  78]]\n",
      "No. of Estimators: 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.88       166\n",
      "           1       0.84      0.75      0.79       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.83      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[151  15]\n",
      " [ 25  76]]\n",
      "No. of Estimators: 17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89       166\n",
      "           1       0.83      0.79      0.81       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.86      0.85      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[150  16]\n",
      " [ 21  80]]\n",
      "No. of Estimators: 18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.88       166\n",
      "           1       0.84      0.75      0.79       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.83      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[151  15]\n",
      " [ 25  76]]\n",
      "No. of Estimators: 19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89       166\n",
      "           1       0.82      0.79      0.81       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.85      0.84      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[149  17]\n",
      " [ 21  80]]\n",
      "No. of Estimators: 20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89       166\n",
      "           1       0.85      0.78      0.81       101\n",
      "\n",
      "    accuracy                           0.87       267\n",
      "   macro avg       0.86      0.85      0.85       267\n",
      "weighted avg       0.86      0.87      0.86       267\n",
      "\n",
      "[[152  14]\n",
      " [ 22  79]]\n",
      "No. of Estimators: 21\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.88       166\n",
      "           1       0.82      0.78      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[149  17]\n",
      " [ 22  79]]\n",
      "No. of Estimators: 22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89       166\n",
      "           1       0.85      0.78      0.81       101\n",
      "\n",
      "    accuracy                           0.87       267\n",
      "   macro avg       0.86      0.85      0.85       267\n",
      "weighted avg       0.86      0.87      0.86       267\n",
      "\n",
      "[[152  14]\n",
      " [ 22  79]]\n",
      "No. of Estimators: 23\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89       166\n",
      "           1       0.82      0.79      0.81       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.85      0.84      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[149  17]\n",
      " [ 21  80]]\n",
      "No. of Estimators: 24\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90       166\n",
      "           1       0.85      0.79      0.82       101\n",
      "\n",
      "    accuracy                           0.87       267\n",
      "   macro avg       0.86      0.85      0.86       267\n",
      "weighted avg       0.87      0.87      0.87       267\n",
      "\n",
      "[[152  14]\n",
      " [ 21  80]]\n",
      "No. of Estimators: 25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89       166\n",
      "           1       0.84      0.79      0.82       101\n",
      "\n",
      "    accuracy                           0.87       267\n",
      "   macro avg       0.86      0.85      0.85       267\n",
      "weighted avg       0.86      0.87      0.86       267\n",
      "\n",
      "[[151  15]\n",
      " [ 21  80]]\n",
      "No. of Estimators: 26\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89       166\n",
      "           1       0.86      0.76      0.81       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.86      0.84      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[153  13]\n",
      " [ 24  77]]\n",
      "No. of Estimators: 27\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.88       166\n",
      "           1       0.83      0.77      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[150  16]\n",
      " [ 23  78]]\n",
      "No. of Estimators: 28\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89       166\n",
      "           1       0.85      0.76      0.80       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.85      0.84      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[152  14]\n",
      " [ 24  77]]\n",
      "No. of Estimators: 29\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89       166\n",
      "           1       0.84      0.77      0.80       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.85      0.84      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[151  15]\n",
      " [ 23  78]]\n",
      "No. of Estimators: 30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89       166\n",
      "           1       0.84      0.77      0.80       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.85      0.84      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[151  15]\n",
      " [ 23  78]]\n",
      "No. of Estimators: 31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88       166\n",
      "           1       0.81      0.78      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.84      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 22  79]]\n",
      "No. of Estimators: 32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89       166\n",
      "           1       0.85      0.78      0.81       101\n",
      "\n",
      "    accuracy                           0.87       267\n",
      "   macro avg       0.86      0.85      0.85       267\n",
      "weighted avg       0.86      0.87      0.86       267\n",
      "\n",
      "[[152  14]\n",
      " [ 22  79]]\n",
      "No. of Estimators: 33\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88       166\n",
      "           1       0.81      0.78      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.84      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 22  79]]\n",
      "No. of Estimators: 34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89       166\n",
      "           1       0.84      0.78      0.81       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.86      0.85      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[151  15]\n",
      " [ 22  79]]\n",
      "No. of Estimators: 35\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.88       166\n",
      "           1       0.82      0.78      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[149  17]\n",
      " [ 22  79]]\n",
      "No. of Estimators: 36\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.89       166\n",
      "           1       0.84      0.76      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[151  15]\n",
      " [ 24  77]]\n",
      "No. of Estimators: 37\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88       166\n",
      "           1       0.82      0.76      0.79       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.84      0.83      0.83       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[149  17]\n",
      " [ 24  77]]\n",
      "No. of Estimators: 38\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89       166\n",
      "           1       0.85      0.76      0.80       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.85      0.84      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[152  14]\n",
      " [ 24  77]]\n",
      "No. of Estimators: 39\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.88       166\n",
      "           1       0.82      0.77      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.84      0.83      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[149  17]\n",
      " [ 23  78]]\n",
      "No. of Estimators: 40\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88       166\n",
      "           1       0.83      0.76      0.79       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.83      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[150  16]\n",
      " [ 24  77]]\n",
      "No. of Estimators: 41\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88       166\n",
      "           1       0.81      0.78      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.84      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 22  79]]\n",
      "No. of Estimators: 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88       166\n",
      "           1       0.82      0.76      0.79       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.84      0.83      0.83       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[149  17]\n",
      " [ 24  77]]\n",
      "No. of Estimators: 43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.89       166\n",
      "           1       0.82      0.80      0.81       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.85      0.85      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[148  18]\n",
      " [ 20  81]]\n",
      "No. of Estimators: 44\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89       166\n",
      "           1       0.82      0.79      0.81       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.85      0.84      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[149  17]\n",
      " [ 21  80]]\n",
      "No. of Estimators: 45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89       166\n",
      "           1       0.82      0.79      0.81       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.85      0.84      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[149  17]\n",
      " [ 21  80]]\n",
      "No. of Estimators: 46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.88       166\n",
      "           1       0.82      0.78      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[149  17]\n",
      " [ 22  79]]\n",
      "No. of Estimators: 47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88       166\n",
      "           1       0.81      0.78      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.84      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 22  79]]\n",
      "No. of Estimators: 48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.89       166\n",
      "           1       0.83      0.78      0.81       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.85      0.84      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[150  16]\n",
      " [ 22  79]]\n",
      "No. of Estimators: 49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       166\n",
      "           1       0.82      0.79      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 21  80]]\n",
      "No. of Estimators: 50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89       166\n",
      "           1       0.84      0.78      0.81       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.86      0.85      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[151  15]\n",
      " [ 22  79]]\n",
      "No. of Estimators: 51\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89       166\n",
      "           1       0.84      0.80      0.82       101\n",
      "\n",
      "    accuracy                           0.87       267\n",
      "   macro avg       0.86      0.85      0.86       267\n",
      "weighted avg       0.86      0.87      0.86       267\n",
      "\n",
      "[[150  16]\n",
      " [ 20  81]]\n",
      "No. of Estimators: 52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.89       166\n",
      "           1       0.83      0.78      0.81       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.85      0.84      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[150  16]\n",
      " [ 22  79]]\n",
      "No. of Estimators: 53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89       166\n",
      "           1       0.83      0.79      0.81       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.86      0.85      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[150  16]\n",
      " [ 21  80]]\n",
      "No. of Estimators: 54\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89       166\n",
      "           1       0.84      0.79      0.82       101\n",
      "\n",
      "    accuracy                           0.87       267\n",
      "   macro avg       0.86      0.85      0.85       267\n",
      "weighted avg       0.86      0.87      0.86       267\n",
      "\n",
      "[[151  15]\n",
      " [ 21  80]]\n",
      "No. of Estimators: 55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89       166\n",
      "           1       0.84      0.80      0.82       101\n",
      "\n",
      "    accuracy                           0.87       267\n",
      "   macro avg       0.86      0.85      0.86       267\n",
      "weighted avg       0.86      0.87      0.86       267\n",
      "\n",
      "[[150  16]\n",
      " [ 20  81]]\n",
      "No. of Estimators: 56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89       166\n",
      "           1       0.84      0.79      0.82       101\n",
      "\n",
      "    accuracy                           0.87       267\n",
      "   macro avg       0.86      0.85      0.85       267\n",
      "weighted avg       0.86      0.87      0.86       267\n",
      "\n",
      "[[151  15]\n",
      " [ 21  80]]\n",
      "No. of Estimators: 57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89       166\n",
      "           1       0.83      0.80      0.81       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.85      0.85      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[149  17]\n",
      " [ 20  81]]\n",
      "No. of Estimators: 58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.88       166\n",
      "           1       0.82      0.78      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[149  17]\n",
      " [ 22  79]]\n",
      "No. of Estimators: 59\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.89       166\n",
      "           1       0.82      0.80      0.81       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.85      0.85      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[148  18]\n",
      " [ 20  81]]\n",
      "No. of Estimators: 60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89       166\n",
      "           1       0.83      0.79      0.81       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.86      0.85      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[150  16]\n",
      " [ 21  80]]\n",
      "No. of Estimators: 61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89       166\n",
      "           1       0.84      0.80      0.82       101\n",
      "\n",
      "    accuracy                           0.87       267\n",
      "   macro avg       0.86      0.85      0.86       267\n",
      "weighted avg       0.86      0.87      0.86       267\n",
      "\n",
      "[[150  16]\n",
      " [ 20  81]]\n",
      "No. of Estimators: 62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89       166\n",
      "           1       0.83      0.79      0.81       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.86      0.85      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[150  16]\n",
      " [ 21  80]]\n",
      "No. of Estimators: 63\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89       166\n",
      "           1       0.83      0.79      0.81       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.86      0.85      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[150  16]\n",
      " [ 21  80]]\n",
      "No. of Estimators: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89       166\n",
      "           1       0.83      0.79      0.81       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.86      0.85      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[150  16]\n",
      " [ 21  80]]\n",
      "No. of Estimators: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89       166\n",
      "           1       0.84      0.80      0.82       101\n",
      "\n",
      "    accuracy                           0.87       267\n",
      "   macro avg       0.86      0.85      0.86       267\n",
      "weighted avg       0.86      0.87      0.86       267\n",
      "\n",
      "[[150  16]\n",
      " [ 20  81]]\n",
      "No. of Estimators: 66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89       166\n",
      "           1       0.84      0.79      0.82       101\n",
      "\n",
      "    accuracy                           0.87       267\n",
      "   macro avg       0.86      0.85      0.85       267\n",
      "weighted avg       0.86      0.87      0.86       267\n",
      "\n",
      "[[151  15]\n",
      " [ 21  80]]\n",
      "No. of Estimators: 67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.90       166\n",
      "           1       0.84      0.80      0.82       101\n",
      "\n",
      "    accuracy                           0.87       267\n",
      "   macro avg       0.86      0.86      0.86       267\n",
      "weighted avg       0.87      0.87      0.87       267\n",
      "\n",
      "[[151  15]\n",
      " [ 20  81]]\n",
      "No. of Estimators: 68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.90       166\n",
      "           1       0.84      0.80      0.82       101\n",
      "\n",
      "    accuracy                           0.87       267\n",
      "   macro avg       0.86      0.86      0.86       267\n",
      "weighted avg       0.87      0.87      0.87       267\n",
      "\n",
      "[[151  15]\n",
      " [ 20  81]]\n",
      "No. of Estimators: 69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90       166\n",
      "           1       0.85      0.81      0.83       101\n",
      "\n",
      "    accuracy                           0.87       267\n",
      "   macro avg       0.87      0.86      0.86       267\n",
      "weighted avg       0.87      0.87      0.87       267\n",
      "\n",
      "[[151  15]\n",
      " [ 19  82]]\n",
      "No. of Estimators: 70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.90       166\n",
      "           1       0.85      0.81      0.83       101\n",
      "\n",
      "    accuracy                           0.88       267\n",
      "   macro avg       0.87      0.86      0.87       267\n",
      "weighted avg       0.88      0.88      0.88       267\n",
      "\n",
      "[[152  14]\n",
      " [ 19  82]]\n",
      "No. of Estimators: 71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.90       166\n",
      "           1       0.85      0.81      0.83       101\n",
      "\n",
      "    accuracy                           0.88       267\n",
      "   macro avg       0.87      0.86      0.87       267\n",
      "weighted avg       0.88      0.88      0.88       267\n",
      "\n",
      "[[152  14]\n",
      " [ 19  82]]\n",
      "No. of Estimators: 72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90       166\n",
      "           1       0.85      0.80      0.83       101\n",
      "\n",
      "    accuracy                           0.87       267\n",
      "   macro avg       0.87      0.86      0.86       267\n",
      "weighted avg       0.87      0.87      0.87       267\n",
      "\n",
      "[[152  14]\n",
      " [ 20  81]]\n",
      "No. of Estimators: 73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90       166\n",
      "           1       0.85      0.81      0.83       101\n",
      "\n",
      "    accuracy                           0.87       267\n",
      "   macro avg       0.87      0.86      0.86       267\n",
      "weighted avg       0.87      0.87      0.87       267\n",
      "\n",
      "[[151  15]\n",
      " [ 19  82]]\n",
      "No. of Estimators: 74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89       166\n",
      "           1       0.84      0.79      0.82       101\n",
      "\n",
      "    accuracy                           0.87       267\n",
      "   macro avg       0.86      0.85      0.85       267\n",
      "weighted avg       0.86      0.87      0.86       267\n",
      "\n",
      "[[151  15]\n",
      " [ 21  80]]\n",
      "No. of Estimators: 75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.90       166\n",
      "           1       0.84      0.80      0.82       101\n",
      "\n",
      "    accuracy                           0.87       267\n",
      "   macro avg       0.86      0.86      0.86       267\n",
      "weighted avg       0.87      0.87      0.87       267\n",
      "\n",
      "[[151  15]\n",
      " [ 20  81]]\n",
      "No. of Estimators: 76\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90       166\n",
      "           1       0.85      0.79      0.82       101\n",
      "\n",
      "    accuracy                           0.87       267\n",
      "   macro avg       0.86      0.85      0.86       267\n",
      "weighted avg       0.87      0.87      0.87       267\n",
      "\n",
      "[[152  14]\n",
      " [ 21  80]]\n",
      "No. of Estimators: 77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89       166\n",
      "           1       0.84      0.79      0.82       101\n",
      "\n",
      "    accuracy                           0.87       267\n",
      "   macro avg       0.86      0.85      0.85       267\n",
      "weighted avg       0.86      0.87      0.86       267\n",
      "\n",
      "[[151  15]\n",
      " [ 21  80]]\n",
      "No. of Estimators: 78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90       166\n",
      "           1       0.85      0.79      0.82       101\n",
      "\n",
      "    accuracy                           0.87       267\n",
      "   macro avg       0.86      0.85      0.86       267\n",
      "weighted avg       0.87      0.87      0.87       267\n",
      "\n",
      "[[152  14]\n",
      " [ 21  80]]\n",
      "No. of Estimators: 79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89       166\n",
      "           1       0.84      0.79      0.82       101\n",
      "\n",
      "    accuracy                           0.87       267\n",
      "   macro avg       0.86      0.85      0.85       267\n",
      "weighted avg       0.86      0.87      0.86       267\n",
      "\n",
      "[[151  15]\n",
      " [ 21  80]]\n",
      "No. of Estimators: 80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89       166\n",
      "           1       0.84      0.79      0.82       101\n",
      "\n",
      "    accuracy                           0.87       267\n",
      "   macro avg       0.86      0.85      0.85       267\n",
      "weighted avg       0.86      0.87      0.86       267\n",
      "\n",
      "[[151  15]\n",
      " [ 21  80]]\n",
      "No. of Estimators: 81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89       166\n",
      "           1       0.83      0.79      0.81       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.86      0.85      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[150  16]\n",
      " [ 21  80]]\n",
      "No. of Estimators: 82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89       166\n",
      "           1       0.84      0.78      0.81       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.86      0.85      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[151  15]\n",
      " [ 22  79]]\n",
      "No. of Estimators: 83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.89       166\n",
      "           1       0.83      0.78      0.81       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.85      0.84      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[150  16]\n",
      " [ 22  79]]\n",
      "No. of Estimators: 84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89       166\n",
      "           1       0.85      0.78      0.81       101\n",
      "\n",
      "    accuracy                           0.87       267\n",
      "   macro avg       0.86      0.85      0.85       267\n",
      "weighted avg       0.86      0.87      0.86       267\n",
      "\n",
      "[[152  14]\n",
      " [ 22  79]]\n",
      "No. of Estimators: 85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89       166\n",
      "           1       0.84      0.78      0.81       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.86      0.85      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[151  15]\n",
      " [ 22  79]]\n",
      "No. of Estimators: 86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89       166\n",
      "           1       0.85      0.78      0.81       101\n",
      "\n",
      "    accuracy                           0.87       267\n",
      "   macro avg       0.86      0.85      0.85       267\n",
      "weighted avg       0.86      0.87      0.86       267\n",
      "\n",
      "[[152  14]\n",
      " [ 22  79]]\n",
      "No. of Estimators: 87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89       166\n",
      "           1       0.84      0.79      0.82       101\n",
      "\n",
      "    accuracy                           0.87       267\n",
      "   macro avg       0.86      0.85      0.85       267\n",
      "weighted avg       0.86      0.87      0.86       267\n",
      "\n",
      "[[151  15]\n",
      " [ 21  80]]\n",
      "No. of Estimators: 88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90       166\n",
      "           1       0.85      0.79      0.82       101\n",
      "\n",
      "    accuracy                           0.87       267\n",
      "   macro avg       0.86      0.85      0.86       267\n",
      "weighted avg       0.87      0.87      0.87       267\n",
      "\n",
      "[[152  14]\n",
      " [ 21  80]]\n",
      "No. of Estimators: 89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90       166\n",
      "           1       0.85      0.79      0.82       101\n",
      "\n",
      "    accuracy                           0.87       267\n",
      "   macro avg       0.86      0.85      0.86       267\n",
      "weighted avg       0.87      0.87      0.87       267\n",
      "\n",
      "[[152  14]\n",
      " [ 21  80]]\n",
      "No. of Estimators: 90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89       166\n",
      "           1       0.85      0.77      0.81       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.86      0.84      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[152  14]\n",
      " [ 23  78]]\n",
      "No. of Estimators: 91\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89       166\n",
      "           1       0.84      0.79      0.82       101\n",
      "\n",
      "    accuracy                           0.87       267\n",
      "   macro avg       0.86      0.85      0.85       267\n",
      "weighted avg       0.86      0.87      0.86       267\n",
      "\n",
      "[[151  15]\n",
      " [ 21  80]]\n",
      "No. of Estimators: 92\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89       166\n",
      "           1       0.85      0.77      0.81       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.86      0.84      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[152  14]\n",
      " [ 23  78]]\n",
      "No. of Estimators: 93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89       166\n",
      "           1       0.84      0.78      0.81       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.86      0.85      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[151  15]\n",
      " [ 22  79]]\n",
      "No. of Estimators: 94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89       166\n",
      "           1       0.85      0.78      0.81       101\n",
      "\n",
      "    accuracy                           0.87       267\n",
      "   macro avg       0.86      0.85      0.85       267\n",
      "weighted avg       0.86      0.87      0.86       267\n",
      "\n",
      "[[152  14]\n",
      " [ 22  79]]\n",
      "No. of Estimators: 95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89       166\n",
      "           1       0.85      0.78      0.81       101\n",
      "\n",
      "    accuracy                           0.87       267\n",
      "   macro avg       0.86      0.85      0.85       267\n",
      "weighted avg       0.86      0.87      0.86       267\n",
      "\n",
      "[[152  14]\n",
      " [ 22  79]]\n",
      "No. of Estimators: 96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89       166\n",
      "           1       0.85      0.78      0.81       101\n",
      "\n",
      "    accuracy                           0.87       267\n",
      "   macro avg       0.86      0.85      0.85       267\n",
      "weighted avg       0.86      0.87      0.86       267\n",
      "\n",
      "[[152  14]\n",
      " [ 22  79]]\n",
      "No. of Estimators: 97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89       166\n",
      "           1       0.85      0.78      0.81       101\n",
      "\n",
      "    accuracy                           0.87       267\n",
      "   macro avg       0.86      0.85      0.85       267\n",
      "weighted avg       0.86      0.87      0.86       267\n",
      "\n",
      "[[152  14]\n",
      " [ 22  79]]\n",
      "No. of Estimators: 98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89       166\n",
      "           1       0.86      0.77      0.81       101\n",
      "\n",
      "    accuracy                           0.87       267\n",
      "   macro avg       0.86      0.85      0.85       267\n",
      "weighted avg       0.86      0.87      0.86       267\n",
      "\n",
      "[[153  13]\n",
      " [ 23  78]]\n",
      "No. of Estimators: 99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89       166\n",
      "           1       0.85      0.77      0.81       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.86      0.84      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[152  14]\n",
      " [ 23  78]]\n",
      "No. of Estimators: 100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89       166\n",
      "           1       0.85      0.77      0.81       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.86      0.84      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[152  14]\n",
      " [ 23  78]]\n"
     ]
    }
   ],
   "source": [
    "#Syntax :- RandomForestClassifier(n_estimators,random_state=1)\n",
    "#Estimators means to train dataset on multiple algorithm\n",
    "#n means number of DecisionTree , we get n_estimators best score between >=10 and <=100\n",
    "#So we apply for loop\n",
    "for i in range(10,101):\n",
    "    #create an object for RandomForestClassifier class\n",
    "    rfc = RandomForestClassifier(n_estimators=i,random_state=1)\n",
    "    print(\"No. of Estimators:\",i)\n",
    "    #call function\n",
    "    rfc = create_model(rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "155713e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89       166\n",
      "           1       0.84      0.80      0.82       101\n",
      "\n",
      "    accuracy                           0.87       267\n",
      "   macro avg       0.86      0.85      0.86       267\n",
      "weighted avg       0.86      0.87      0.86       267\n",
      "\n",
      "[[150  16]\n",
      " [ 20  81]]\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=55,random_state=1) #By defualt take GINI Index\n",
    "#call function\n",
    "rfc = create_model(rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "32c88f35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>IG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sex</td>\n",
       "      <td>0.218080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ticket</td>\n",
       "      <td>0.156629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.125998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fare</td>\n",
       "      <td>0.125487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PassengerId</td>\n",
       "      <td>0.117815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Name</td>\n",
       "      <td>0.114370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pclass</td>\n",
       "      <td>0.064704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Embarked</td>\n",
       "      <td>0.026820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Parch</td>\n",
       "      <td>0.026049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SibSp</td>\n",
       "      <td>0.024048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Input        IG\n",
       "0          Sex  0.218080\n",
       "1       Ticket  0.156629\n",
       "2          Age  0.125998\n",
       "3         Fare  0.125487\n",
       "4  PassengerId  0.117815\n",
       "5         Name  0.114370\n",
       "6       Pclass  0.064704\n",
       "7     Embarked  0.026820\n",
       "8        Parch  0.026049\n",
       "9        SibSp  0.024048"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now check information gain(IG)\n",
    "dict7 = {\"Input\":x.columns,\"IG\":rfc.feature_importances_}\n",
    "df8 = pd.DataFrame(dict7)\n",
    "df8.sort_values(\"IG\",ascending=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3fe4a4f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Depth: 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.95      0.85       166\n",
      "           1       0.87      0.51      0.65       101\n",
      "\n",
      "    accuracy                           0.79       267\n",
      "   macro avg       0.81      0.73      0.75       267\n",
      "weighted avg       0.80      0.79      0.77       267\n",
      "\n",
      "[[158   8]\n",
      " [ 49  52]]\n",
      "Max Depth: 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.96      0.88       166\n",
      "           1       0.91      0.62      0.74       101\n",
      "\n",
      "    accuracy                           0.84       267\n",
      "   macro avg       0.86      0.79      0.81       267\n",
      "weighted avg       0.85      0.84      0.83       267\n",
      "\n",
      "[[160   6]\n",
      " [ 38  63]]\n",
      "Max Depth: 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.96      0.88       166\n",
      "           1       0.90      0.62      0.74       101\n",
      "\n",
      "    accuracy                           0.83       267\n",
      "   macro avg       0.85      0.79      0.81       267\n",
      "weighted avg       0.84      0.83      0.82       267\n",
      "\n",
      "[[159   7]\n",
      " [ 38  63]]\n",
      "Max Depth: 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.88       166\n",
      "           1       0.88      0.68      0.77       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.86      0.81      0.83       267\n",
      "weighted avg       0.85      0.85      0.84       267\n",
      "\n",
      "[[157   9]\n",
      " [ 32  69]]\n",
      "Max Depth: 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.89       166\n",
      "           1       0.85      0.74      0.79       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.83      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[153  13]\n",
      " [ 26  75]]\n",
      "Max Depth: 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.93      0.89       166\n",
      "           1       0.86      0.73      0.79       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.86      0.83      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[154  12]\n",
      " [ 27  74]]\n",
      "Max Depth: 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90       166\n",
      "           1       0.89      0.76      0.82       101\n",
      "\n",
      "    accuracy                           0.87       267\n",
      "   macro avg       0.88      0.85      0.86       267\n",
      "weighted avg       0.87      0.87      0.87       267\n",
      "\n",
      "[[156  10]\n",
      " [ 24  77]]\n",
      "Max Depth: 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88       166\n",
      "           1       0.83      0.76      0.79       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.83      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[150  16]\n",
      " [ 24  77]]\n"
     ]
    }
   ],
   "source": [
    "#we got recall score 80% wthich is good but not better ,\n",
    "#So we apply pruning tech. for best score\n",
    "#There are 2 type of pruning technique 1.max_depth and 2.min_samples_leaf\n",
    "#1.Apply Max Depth :- get the best score between >=1 to <=8, \n",
    "#so we apply for loop for with range\n",
    "for i in range(1,9):\n",
    "    rfc1 = RandomForestClassifier(n_estimators=55,random_state=1,max_depth=i)\n",
    "    print(\"Max Depth:\",i)\n",
    "    #call function\n",
    "    rfc1 = create_model(rfc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2f1d643f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90       166\n",
      "           1       0.89      0.76      0.82       101\n",
      "\n",
      "    accuracy                           0.87       267\n",
      "   macro avg       0.88      0.85      0.86       267\n",
      "weighted avg       0.87      0.87      0.87       267\n",
      "\n",
      "[[156  10]\n",
      " [ 24  77]]\n"
     ]
    }
   ],
   "source": [
    "#Got the good score at 7\n",
    "rfc1 = RandomForestClassifier(n_estimators=55,random_state=1,max_depth=7)\n",
    "#call function\n",
    "rfc1 = create_model(rfc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c6b009e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>IG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sex</td>\n",
       "      <td>0.294682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ticket</td>\n",
       "      <td>0.133272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fare</td>\n",
       "      <td>0.132365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.106549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Name</td>\n",
       "      <td>0.088397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PassengerId</td>\n",
       "      <td>0.078801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pclass</td>\n",
       "      <td>0.077101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SibSp</td>\n",
       "      <td>0.032934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Parch</td>\n",
       "      <td>0.028404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Embarked</td>\n",
       "      <td>0.027496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Input        IG\n",
       "0          Sex  0.294682\n",
       "1       Ticket  0.133272\n",
       "2         Fare  0.132365\n",
       "3          Age  0.106549\n",
       "4         Name  0.088397\n",
       "5  PassengerId  0.078801\n",
       "6       Pclass  0.077101\n",
       "7        SibSp  0.032934\n",
       "8        Parch  0.028404\n",
       "9     Embarked  0.027496"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now check information gain(IG)\n",
    "dict8 = {\"Input\":x.columns,\"IG\":rfc1.feature_importances_}\n",
    "df9 = pd.DataFrame(dict8)\n",
    "df9.sort_values(\"IG\",ascending=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8bca9506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Samples Leaf: 45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.96      0.88       166\n",
      "           1       0.91      0.61      0.73       101\n",
      "\n",
      "    accuracy                           0.83       267\n",
      "   macro avg       0.86      0.79      0.81       267\n",
      "weighted avg       0.84      0.83      0.82       267\n",
      "\n",
      "[[160   6]\n",
      " [ 39  62]]\n",
      "Min Samples Leaf: 46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.96      0.87       166\n",
      "           1       0.91      0.59      0.72       101\n",
      "\n",
      "    accuracy                           0.82       267\n",
      "   macro avg       0.85      0.78      0.80       267\n",
      "weighted avg       0.84      0.82      0.81       267\n",
      "\n",
      "[[160   6]\n",
      " [ 41  60]]\n",
      "Min Samples Leaf: 47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.96      0.87       166\n",
      "           1       0.91      0.59      0.72       101\n",
      "\n",
      "    accuracy                           0.82       267\n",
      "   macro avg       0.85      0.78      0.80       267\n",
      "weighted avg       0.84      0.82      0.81       267\n",
      "\n",
      "[[160   6]\n",
      " [ 41  60]]\n",
      "Min Samples Leaf: 48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.96      0.87       166\n",
      "           1       0.91      0.59      0.72       101\n",
      "\n",
      "    accuracy                           0.82       267\n",
      "   macro avg       0.85      0.78      0.80       267\n",
      "weighted avg       0.84      0.82      0.81       267\n",
      "\n",
      "[[160   6]\n",
      " [ 41  60]]\n",
      "Min Samples Leaf: 49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.96      0.87       166\n",
      "           1       0.91      0.59      0.72       101\n",
      "\n",
      "    accuracy                           0.82       267\n",
      "   macro avg       0.85      0.78      0.80       267\n",
      "weighted avg       0.84      0.82      0.81       267\n",
      "\n",
      "[[160   6]\n",
      " [ 41  60]]\n",
      "Min Samples Leaf: 50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.96      0.87       166\n",
      "           1       0.91      0.60      0.73       101\n",
      "\n",
      "    accuracy                           0.83       267\n",
      "   macro avg       0.86      0.78      0.80       267\n",
      "weighted avg       0.84      0.83      0.82       267\n",
      "\n",
      "[[160   6]\n",
      " [ 40  61]]\n",
      "Min Samples Leaf: 51\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.96      0.88       166\n",
      "           1       0.91      0.61      0.73       101\n",
      "\n",
      "    accuracy                           0.83       267\n",
      "   macro avg       0.86      0.79      0.81       267\n",
      "weighted avg       0.84      0.83      0.82       267\n",
      "\n",
      "[[160   6]\n",
      " [ 39  62]]\n",
      "Min Samples Leaf: 52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.95      0.87       166\n",
      "           1       0.87      0.60      0.71       101\n",
      "\n",
      "    accuracy                           0.82       267\n",
      "   macro avg       0.83      0.77      0.79       267\n",
      "weighted avg       0.83      0.82      0.81       267\n",
      "\n",
      "[[157   9]\n",
      " [ 40  61]]\n",
      "Min Samples Leaf: 53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.93      0.86       166\n",
      "           1       0.85      0.62      0.72       101\n",
      "\n",
      "    accuracy                           0.82       267\n",
      "   macro avg       0.83      0.78      0.79       267\n",
      "weighted avg       0.82      0.82      0.81       267\n",
      "\n",
      "[[155  11]\n",
      " [ 38  63]]\n",
      "Min Samples Leaf: 54\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.93      0.87       166\n",
      "           1       0.85      0.63      0.73       101\n",
      "\n",
      "    accuracy                           0.82       267\n",
      "   macro avg       0.83      0.78      0.80       267\n",
      "weighted avg       0.82      0.82      0.81       267\n",
      "\n",
      "[[155  11]\n",
      " [ 37  64]]\n",
      "Min Samples Leaf: 55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.92      0.86       166\n",
      "           1       0.82      0.63      0.72       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.81      0.77      0.79       267\n",
      "weighted avg       0.81      0.81      0.80       267\n",
      "\n",
      "[[152  14]\n",
      " [ 37  64]]\n",
      "Min Samples Leaf: 56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.92      0.86       166\n",
      "           1       0.82      0.63      0.72       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.81      0.77      0.79       267\n",
      "weighted avg       0.81      0.81      0.80       267\n",
      "\n",
      "[[152  14]\n",
      " [ 37  64]]\n",
      "Min Samples Leaf: 57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.92      0.86       166\n",
      "           1       0.82      0.63      0.72       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.81      0.77      0.79       267\n",
      "weighted avg       0.81      0.81      0.80       267\n",
      "\n",
      "[[152  14]\n",
      " [ 37  64]]\n",
      "Min Samples Leaf: 58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.91      0.85       166\n",
      "           1       0.81      0.63      0.71       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.81      0.77      0.78       267\n",
      "weighted avg       0.81      0.81      0.80       267\n",
      "\n",
      "[[151  15]\n",
      " [ 37  64]]\n",
      "Min Samples Leaf: 59\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.91      0.85       166\n",
      "           1       0.81      0.63      0.71       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.81      0.77      0.78       267\n",
      "weighted avg       0.81      0.81      0.80       267\n",
      "\n",
      "[[151  15]\n",
      " [ 37  64]]\n",
      "Min Samples Leaf: 60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.91      0.85       166\n",
      "           1       0.81      0.63      0.71       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.81      0.77      0.78       267\n",
      "weighted avg       0.81      0.81      0.80       267\n",
      "\n",
      "[[151  15]\n",
      " [ 37  64]]\n",
      "Min Samples Leaf: 61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.91      0.86       166\n",
      "           1       0.81      0.64      0.72       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.81      0.78      0.79       267\n",
      "weighted avg       0.81      0.81      0.80       267\n",
      "\n",
      "[[151  15]\n",
      " [ 36  65]]\n",
      "Min Samples Leaf: 62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.91      0.86       166\n",
      "           1       0.81      0.64      0.72       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.81      0.78      0.79       267\n",
      "weighted avg       0.81      0.81      0.80       267\n",
      "\n",
      "[[151  15]\n",
      " [ 36  65]]\n",
      "Min Samples Leaf: 63\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.91      0.85       166\n",
      "           1       0.81      0.63      0.71       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.81      0.77      0.78       267\n",
      "weighted avg       0.81      0.81      0.80       267\n",
      "\n",
      "[[151  15]\n",
      " [ 37  64]]\n",
      "Min Samples Leaf: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.91      0.86       166\n",
      "           1       0.81      0.64      0.72       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.81      0.78      0.79       267\n",
      "weighted avg       0.81      0.81      0.80       267\n",
      "\n",
      "[[151  15]\n",
      " [ 36  65]]\n",
      "Min Samples Leaf: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.91      0.86       166\n",
      "           1       0.81      0.64      0.72       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.81      0.78      0.79       267\n",
      "weighted avg       0.81      0.81      0.80       267\n",
      "\n",
      "[[151  15]\n",
      " [ 36  65]]\n",
      "Min Samples Leaf: 66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.91      0.86       166\n",
      "           1       0.81      0.64      0.72       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.81      0.78      0.79       267\n",
      "weighted avg       0.81      0.81      0.80       267\n",
      "\n",
      "[[151  15]\n",
      " [ 36  65]]\n",
      "Min Samples Leaf: 67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.91      0.86       166\n",
      "           1       0.81      0.65      0.73       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.81      0.78      0.79       267\n",
      "weighted avg       0.81      0.81      0.81       267\n",
      "\n",
      "[[151  15]\n",
      " [ 35  66]]\n",
      "Min Samples Leaf: 68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.91      0.86       166\n",
      "           1       0.81      0.65      0.73       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.81      0.78      0.79       267\n",
      "weighted avg       0.81      0.81      0.81       267\n",
      "\n",
      "[[151  15]\n",
      " [ 35  66]]\n",
      "Min Samples Leaf: 69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.91      0.86       166\n",
      "           1       0.81      0.64      0.72       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.81      0.78      0.79       267\n",
      "weighted avg       0.81      0.81      0.80       267\n",
      "\n",
      "[[151  15]\n",
      " [ 36  65]]\n",
      "Min Samples Leaf: 70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.91      0.86       166\n",
      "           1       0.81      0.65      0.73       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.81      0.78      0.79       267\n",
      "weighted avg       0.81      0.81      0.81       267\n",
      "\n",
      "[[151  15]\n",
      " [ 35  66]]\n",
      "Min Samples Leaf: 71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.91      0.86       166\n",
      "           1       0.81      0.64      0.72       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.81      0.78      0.79       267\n",
      "weighted avg       0.81      0.81      0.80       267\n",
      "\n",
      "[[151  15]\n",
      " [ 36  65]]\n",
      "Min Samples Leaf: 72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.91      0.85       166\n",
      "           1       0.81      0.62      0.70       101\n",
      "\n",
      "    accuracy                           0.80       267\n",
      "   macro avg       0.80      0.77      0.78       267\n",
      "weighted avg       0.80      0.80      0.80       267\n",
      "\n",
      "[[151  15]\n",
      " [ 38  63]]\n",
      "Min Samples Leaf: 73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.91      0.85       166\n",
      "           1       0.81      0.63      0.71       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.81      0.77      0.78       267\n",
      "weighted avg       0.81      0.81      0.80       267\n",
      "\n",
      "[[151  15]\n",
      " [ 37  64]]\n",
      "Min Samples Leaf: 74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.91      0.85       166\n",
      "           1       0.81      0.63      0.71       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.81      0.77      0.78       267\n",
      "weighted avg       0.81      0.81      0.80       267\n",
      "\n",
      "[[151  15]\n",
      " [ 37  64]]\n",
      "Min Samples Leaf: 75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.91      0.85       166\n",
      "           1       0.81      0.63      0.71       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.81      0.77      0.78       267\n",
      "weighted avg       0.81      0.81      0.80       267\n",
      "\n",
      "[[151  15]\n",
      " [ 37  64]]\n",
      "Min Samples Leaf: 76\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.91      0.85       166\n",
      "           1       0.81      0.63      0.71       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.81      0.77      0.78       267\n",
      "weighted avg       0.81      0.81      0.80       267\n",
      "\n",
      "[[151  15]\n",
      " [ 37  64]]\n",
      "Min Samples Leaf: 77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.91      0.86       166\n",
      "           1       0.81      0.64      0.72       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.81      0.78      0.79       267\n",
      "weighted avg       0.81      0.81      0.80       267\n",
      "\n",
      "[[151  15]\n",
      " [ 36  65]]\n",
      "Min Samples Leaf: 78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.91      0.85       166\n",
      "           1       0.81      0.62      0.70       101\n",
      "\n",
      "    accuracy                           0.80       267\n",
      "   macro avg       0.80      0.77      0.78       267\n",
      "weighted avg       0.80      0.80      0.80       267\n",
      "\n",
      "[[151  15]\n",
      " [ 38  63]]\n",
      "Min Samples Leaf: 79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.91      0.85       166\n",
      "           1       0.80      0.60      0.69       101\n",
      "\n",
      "    accuracy                           0.79       267\n",
      "   macro avg       0.80      0.76      0.77       267\n",
      "weighted avg       0.80      0.79      0.79       267\n",
      "\n",
      "[[151  15]\n",
      " [ 40  61]]\n",
      "Min Samples Leaf: 80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.91      0.85       166\n",
      "           1       0.80      0.60      0.69       101\n",
      "\n",
      "    accuracy                           0.79       267\n",
      "   macro avg       0.80      0.76      0.77       267\n",
      "weighted avg       0.80      0.79      0.79       267\n",
      "\n",
      "[[151  15]\n",
      " [ 40  61]]\n",
      "Min Samples Leaf: 81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.91      0.85       166\n",
      "           1       0.80      0.60      0.69       101\n",
      "\n",
      "    accuracy                           0.79       267\n",
      "   macro avg       0.80      0.76      0.77       267\n",
      "weighted avg       0.80      0.79      0.79       267\n",
      "\n",
      "[[151  15]\n",
      " [ 40  61]]\n",
      "Min Samples Leaf: 82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.91      0.85       166\n",
      "           1       0.80      0.60      0.69       101\n",
      "\n",
      "    accuracy                           0.79       267\n",
      "   macro avg       0.80      0.76      0.77       267\n",
      "weighted avg       0.80      0.79      0.79       267\n",
      "\n",
      "[[151  15]\n",
      " [ 40  61]]\n",
      "Min Samples Leaf: 83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.91      0.85       166\n",
      "           1       0.80      0.60      0.69       101\n",
      "\n",
      "    accuracy                           0.79       267\n",
      "   macro avg       0.80      0.76      0.77       267\n",
      "weighted avg       0.80      0.79      0.79       267\n",
      "\n",
      "[[151  15]\n",
      " [ 40  61]]\n",
      "Min Samples Leaf: 84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.91      0.84       166\n",
      "           1       0.80      0.58      0.67       101\n",
      "\n",
      "    accuracy                           0.79       267\n",
      "   macro avg       0.79      0.75      0.76       267\n",
      "weighted avg       0.79      0.79      0.78       267\n",
      "\n",
      "[[151  15]\n",
      " [ 42  59]]\n",
      "Min Samples Leaf: 85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.91      0.84       166\n",
      "           1       0.80      0.58      0.67       101\n",
      "\n",
      "    accuracy                           0.79       267\n",
      "   macro avg       0.79      0.75      0.76       267\n",
      "weighted avg       0.79      0.79      0.78       267\n",
      "\n",
      "[[151  15]\n",
      " [ 42  59]]\n",
      "Min Samples Leaf: 86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.91      0.84       166\n",
      "           1       0.80      0.58      0.67       101\n",
      "\n",
      "    accuracy                           0.79       267\n",
      "   macro avg       0.79      0.75      0.76       267\n",
      "weighted avg       0.79      0.79      0.78       267\n",
      "\n",
      "[[151  15]\n",
      " [ 42  59]]\n",
      "Min Samples Leaf: 87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.91      0.84       166\n",
      "           1       0.80      0.58      0.67       101\n",
      "\n",
      "    accuracy                           0.79       267\n",
      "   macro avg       0.79      0.75      0.76       267\n",
      "weighted avg       0.79      0.79      0.78       267\n",
      "\n",
      "[[151  15]\n",
      " [ 42  59]]\n",
      "Min Samples Leaf: 88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.91      0.84       166\n",
      "           1       0.79      0.57      0.67       101\n",
      "\n",
      "    accuracy                           0.78       267\n",
      "   macro avg       0.79      0.74      0.75       267\n",
      "weighted avg       0.78      0.78      0.77       267\n",
      "\n",
      "[[151  15]\n",
      " [ 43  58]]\n",
      "Min Samples Leaf: 89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.91      0.84       166\n",
      "           1       0.79      0.56      0.66       101\n",
      "\n",
      "    accuracy                           0.78       267\n",
      "   macro avg       0.78      0.74      0.75       267\n",
      "weighted avg       0.78      0.78      0.77       267\n",
      "\n",
      "[[151  15]\n",
      " [ 44  57]]\n",
      "Min Samples Leaf: 90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.91      0.84       166\n",
      "           1       0.80      0.58      0.67       101\n",
      "\n",
      "    accuracy                           0.79       267\n",
      "   macro avg       0.79      0.75      0.76       267\n",
      "weighted avg       0.79      0.79      0.78       267\n",
      "\n",
      "[[151  15]\n",
      " [ 42  59]]\n",
      "Min Samples Leaf: 91\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.91      0.84       166\n",
      "           1       0.79      0.57      0.67       101\n",
      "\n",
      "    accuracy                           0.78       267\n",
      "   macro avg       0.79      0.74      0.75       267\n",
      "weighted avg       0.78      0.78      0.77       267\n",
      "\n",
      "[[151  15]\n",
      " [ 43  58]]\n",
      "Min Samples Leaf: 92\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.91      0.84       166\n",
      "           1       0.79      0.57      0.67       101\n",
      "\n",
      "    accuracy                           0.78       267\n",
      "   macro avg       0.79      0.74      0.75       267\n",
      "weighted avg       0.78      0.78      0.77       267\n",
      "\n",
      "[[151  15]\n",
      " [ 43  58]]\n",
      "Min Samples Leaf: 93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.91      0.84       166\n",
      "           1       0.79      0.57      0.67       101\n",
      "\n",
      "    accuracy                           0.78       267\n",
      "   macro avg       0.79      0.74      0.75       267\n",
      "weighted avg       0.78      0.78      0.77       267\n",
      "\n",
      "[[151  15]\n",
      " [ 43  58]]\n",
      "Min Samples Leaf: 94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.92      0.84       166\n",
      "           1       0.80      0.54      0.65       101\n",
      "\n",
      "    accuracy                           0.78       267\n",
      "   macro avg       0.78      0.73      0.74       267\n",
      "weighted avg       0.78      0.78      0.76       267\n",
      "\n",
      "[[152  14]\n",
      " [ 46  55]]\n",
      "Min Samples Leaf: 95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.91      0.83       166\n",
      "           1       0.79      0.54      0.64       101\n",
      "\n",
      "    accuracy                           0.77       267\n",
      "   macro avg       0.78      0.73      0.74       267\n",
      "weighted avg       0.77      0.77      0.76       267\n",
      "\n",
      "[[151  15]\n",
      " [ 46  55]]\n",
      "Min Samples Leaf: 96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.91      0.83       166\n",
      "           1       0.79      0.54      0.64       101\n",
      "\n",
      "    accuracy                           0.77       267\n",
      "   macro avg       0.78      0.73      0.74       267\n",
      "weighted avg       0.77      0.77      0.76       267\n",
      "\n",
      "[[151  15]\n",
      " [ 46  55]]\n",
      "Min Samples Leaf: 97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.91      0.83       166\n",
      "           1       0.79      0.54      0.64       101\n",
      "\n",
      "    accuracy                           0.77       267\n",
      "   macro avg       0.78      0.73      0.74       267\n",
      "weighted avg       0.77      0.77      0.76       267\n",
      "\n",
      "[[151  15]\n",
      " [ 46  55]]\n",
      "Min Samples Leaf: 98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.95      0.85       166\n",
      "           1       0.86      0.54      0.67       101\n",
      "\n",
      "    accuracy                           0.79       267\n",
      "   macro avg       0.82      0.75      0.76       267\n",
      "weighted avg       0.81      0.79      0.78       267\n",
      "\n",
      "[[157   9]\n",
      " [ 46  55]]\n",
      "Min Samples Leaf: 99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.96      0.86       166\n",
      "           1       0.90      0.54      0.68       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.84      0.75      0.77       267\n",
      "weighted avg       0.82      0.81      0.79       267\n",
      "\n",
      "[[160   6]\n",
      " [ 46  55]]\n",
      "Min Samples Leaf: 100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.96      0.86       166\n",
      "           1       0.90      0.56      0.70       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.84      0.76      0.78       267\n",
      "weighted avg       0.83      0.81      0.80       267\n",
      "\n",
      "[[160   6]\n",
      " [ 44  57]]\n"
     ]
    }
   ],
   "source": [
    "#2. Apply Min Samples Leaf : get the best score between >=45 and <=100\n",
    "#So we apply for-loop to check the best score\n",
    "for i in range(45,101):\n",
    "    rfc2 = RandomForestClassifier(n_estimators=55,random_state=1,min_samples_leaf=i)\n",
    "    print(\"Min Samples Leaf:\",i)\n",
    "    #call function\n",
    "    rfc2 = create_model(rfc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7936b286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.91      0.86       166\n",
      "           1       0.81      0.65      0.73       101\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.81      0.78      0.79       267\n",
      "weighted avg       0.81      0.81      0.81       267\n",
      "\n",
      "[[151  15]\n",
      " [ 35  66]]\n"
     ]
    }
   ],
   "source": [
    "#got good score at 67\n",
    "rfc2 = RandomForestClassifier(n_estimators=55,random_state=1,min_samples_leaf=67)\n",
    "#call function\n",
    "rfc2 = create_model(rfc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "92069577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>IG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sex</td>\n",
       "      <td>0.459915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fare</td>\n",
       "      <td>0.188236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pclass</td>\n",
       "      <td>0.127180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ticket</td>\n",
       "      <td>0.104046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Embarked</td>\n",
       "      <td>0.044415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Parch</td>\n",
       "      <td>0.024784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PassengerId</td>\n",
       "      <td>0.020476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.015782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Name</td>\n",
       "      <td>0.011233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SibSp</td>\n",
       "      <td>0.003933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Input        IG\n",
       "0          Sex  0.459915\n",
       "1         Fare  0.188236\n",
       "2       Pclass  0.127180\n",
       "3       Ticket  0.104046\n",
       "4     Embarked  0.044415\n",
       "5        Parch  0.024784\n",
       "6  PassengerId  0.020476\n",
       "7          Age  0.015782\n",
       "8         Name  0.011233\n",
       "9        SibSp  0.003933"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now check information gain(IG)\n",
    "dict9 = {\"Input\":x.columns,\"IG\":rfc2.feature_importances_}\n",
    "df10 = pd.DataFrame(dict9)\n",
    "df10.sort_values(\"IG\",ascending=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1a21ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#While applying Random Forest Classifier we got recall score in\n",
    "#max_depth :- 0.76(76%) and\n",
    "#min_samples_leaf :- 0.65(65%) \n",
    "#Which is not the best score so we apply boosting technique on our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d1f6f6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boosting Technique\n",
    "#1.ADA Boosting :- it is inbuilt class of ensemble outer class from sklearn package\n",
    "from sklearn.ensemble import AdaBoostClassifier   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2d1f0e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Estimators: 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86       166\n",
      "           1       0.77      0.74      0.76       101\n",
      "\n",
      "    accuracy                           0.82       267\n",
      "   macro avg       0.81      0.81      0.81       267\n",
      "weighted avg       0.82      0.82      0.82       267\n",
      "\n",
      "[[144  22]\n",
      " [ 26  75]]\n",
      "No. of Estimators: 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86       166\n",
      "           1       0.77      0.74      0.76       101\n",
      "\n",
      "    accuracy                           0.82       267\n",
      "   macro avg       0.81      0.81      0.81       267\n",
      "weighted avg       0.82      0.82      0.82       267\n",
      "\n",
      "[[144  22]\n",
      " [ 26  75]]\n",
      "No. of Estimators: 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.86       166\n",
      "           1       0.78      0.76      0.77       101\n",
      "\n",
      "    accuracy                           0.83       267\n",
      "   macro avg       0.82      0.81      0.82       267\n",
      "weighted avg       0.83      0.83      0.83       267\n",
      "\n",
      "[[144  22]\n",
      " [ 24  77]]\n",
      "No. of Estimators: 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.78      0.82       166\n",
      "           1       0.69      0.80      0.74       101\n",
      "\n",
      "    accuracy                           0.79       267\n",
      "   macro avg       0.78      0.79      0.78       267\n",
      "weighted avg       0.80      0.79      0.79       267\n",
      "\n",
      "[[130  36]\n",
      " [ 20  81]]\n",
      "No. of Estimators: 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.81      0.83       166\n",
      "           1       0.71      0.79      0.75       101\n",
      "\n",
      "    accuracy                           0.80       267\n",
      "   macro avg       0.79      0.80      0.79       267\n",
      "weighted avg       0.81      0.80      0.80       267\n",
      "\n",
      "[[134  32]\n",
      " [ 21  80]]\n",
      "No. of Estimators: 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.84      0.86       166\n",
      "           1       0.75      0.79      0.77       101\n",
      "\n",
      "    accuracy                           0.82       267\n",
      "   macro avg       0.81      0.82      0.81       267\n",
      "weighted avg       0.83      0.82      0.82       267\n",
      "\n",
      "[[140  26]\n",
      " [ 21  80]]\n",
      "No. of Estimators: 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.83      0.86       166\n",
      "           1       0.75      0.83      0.79       101\n",
      "\n",
      "    accuracy                           0.83       267\n",
      "   macro avg       0.82      0.83      0.82       267\n",
      "weighted avg       0.84      0.83      0.83       267\n",
      "\n",
      "[[138  28]\n",
      " [ 17  84]]\n",
      "No. of Estimators: 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.84      0.86       166\n",
      "           1       0.75      0.81      0.78       101\n",
      "\n",
      "    accuracy                           0.83       267\n",
      "   macro avg       0.82      0.82      0.82       267\n",
      "weighted avg       0.83      0.83      0.83       267\n",
      "\n",
      "[[139  27]\n",
      " [ 19  82]]\n",
      "No. of Estimators: 9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.84      0.86       166\n",
      "           1       0.75      0.79      0.77       101\n",
      "\n",
      "    accuracy                           0.82       267\n",
      "   macro avg       0.81      0.82      0.81       267\n",
      "weighted avg       0.83      0.82      0.82       267\n",
      "\n",
      "[[140  26]\n",
      " [ 21  80]]\n",
      "No. of Estimators: 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.85      0.86       166\n",
      "           1       0.76      0.80      0.78       101\n",
      "\n",
      "    accuracy                           0.83       267\n",
      "   macro avg       0.82      0.83      0.82       267\n",
      "weighted avg       0.83      0.83      0.83       267\n",
      "\n",
      "[[141  25]\n",
      " [ 20  81]]\n"
     ]
    }
   ],
   "source": [
    "#instaed of hit and trail method we use for loop for better score\n",
    "for i in range(1,11):\n",
    "    ada = AdaBoostClassifier(n_estimators=i,random_state=1)\n",
    "    print(\"No. of Estimators:\",i)\n",
    "    #call function\n",
    "    ada = create_model(ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e6ced83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.83      0.86       166\n",
      "           1       0.75      0.83      0.79       101\n",
      "\n",
      "    accuracy                           0.83       267\n",
      "   macro avg       0.82      0.83      0.82       267\n",
      "weighted avg       0.84      0.83      0.83       267\n",
      "\n",
      "[[138  28]\n",
      " [ 17  84]]\n"
     ]
    }
   ],
   "source": [
    "#we got good score at 7 estimator\n",
    "ada = AdaBoostClassifier(n_estimators=7,random_state=1)\n",
    "#here n_estimator means number of input in our given dataset which is 10\n",
    "#call function\n",
    "ada = create_model(ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e5095bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>IG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pclass</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SibSp</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sex</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ticket</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Embarked</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PassengerId</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Parch</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Fare</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Name</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Input        IG\n",
       "0          Age  0.285714\n",
       "1       Pclass  0.142857\n",
       "2        SibSp  0.142857\n",
       "3          Sex  0.142857\n",
       "4       Ticket  0.142857\n",
       "5     Embarked  0.142857\n",
       "6  PassengerId  0.000000\n",
       "7        Parch  0.000000\n",
       "8         Fare  0.000000\n",
       "9         Name  0.000000"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now check information gain(IG)\n",
    "dict10 = {\"Input\":x.columns,\"IG\":ada.feature_importances_}\n",
    "df11 = pd.DataFrame(dict10)\n",
    "df11.sort_values(\"IG\",ascending=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "575b0d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#while applying ADA Boosting Classifier we got recall value 0.83(83%) which is good but not better\n",
    "#Now we apply 2nd Boosting which is Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e2381141",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient Boosting :- Its basically focus on short coming error means full grown tree\n",
    "#call inbuilt class for GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d1bdbeca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Estimators: 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.94      0.87       166\n",
      "           1       0.86      0.63      0.73       101\n",
      "\n",
      "    accuracy                           0.82       267\n",
      "   macro avg       0.84      0.79      0.80       267\n",
      "weighted avg       0.83      0.82      0.82       267\n",
      "\n",
      "[[156  10]\n",
      " [ 37  64]]\n",
      "No. of Estimators: 11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.94      0.87       166\n",
      "           1       0.86      0.63      0.73       101\n",
      "\n",
      "    accuracy                           0.82       267\n",
      "   macro avg       0.84      0.79      0.80       267\n",
      "weighted avg       0.83      0.82      0.82       267\n",
      "\n",
      "[[156  10]\n",
      " [ 37  64]]\n",
      "No. of Estimators: 12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.94      0.87       166\n",
      "           1       0.86      0.63      0.73       101\n",
      "\n",
      "    accuracy                           0.82       267\n",
      "   macro avg       0.84      0.79      0.80       267\n",
      "weighted avg       0.83      0.82      0.82       267\n",
      "\n",
      "[[156  10]\n",
      " [ 37  64]]\n",
      "No. of Estimators: 13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.94      0.87       166\n",
      "           1       0.87      0.64      0.74       101\n",
      "\n",
      "    accuracy                           0.83       267\n",
      "   macro avg       0.84      0.79      0.81       267\n",
      "weighted avg       0.83      0.83      0.82       267\n",
      "\n",
      "[[156  10]\n",
      " [ 36  65]]\n",
      "No. of Estimators: 14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.94      0.87       166\n",
      "           1       0.86      0.63      0.73       101\n",
      "\n",
      "    accuracy                           0.82       267\n",
      "   macro avg       0.84      0.79      0.80       267\n",
      "weighted avg       0.83      0.82      0.82       267\n",
      "\n",
      "[[156  10]\n",
      " [ 37  64]]\n",
      "No. of Estimators: 15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.94      0.87       166\n",
      "           1       0.87      0.64      0.74       101\n",
      "\n",
      "    accuracy                           0.83       267\n",
      "   macro avg       0.84      0.79      0.81       267\n",
      "weighted avg       0.83      0.83      0.82       267\n",
      "\n",
      "[[156  10]\n",
      " [ 36  65]]\n",
      "No. of Estimators: 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88       166\n",
      "           1       0.87      0.67      0.76       101\n",
      "\n",
      "    accuracy                           0.84       267\n",
      "   macro avg       0.85      0.81      0.82       267\n",
      "weighted avg       0.84      0.84      0.83       267\n",
      "\n",
      "[[156  10]\n",
      " [ 33  68]]\n",
      "No. of Estimators: 17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.88       166\n",
      "           1       0.87      0.66      0.75       101\n",
      "\n",
      "    accuracy                           0.84       267\n",
      "   macro avg       0.85      0.80      0.81       267\n",
      "weighted avg       0.84      0.84      0.83       267\n",
      "\n",
      "[[156  10]\n",
      " [ 34  67]]\n",
      "No. of Estimators: 18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88       166\n",
      "           1       0.87      0.68      0.77       101\n",
      "\n",
      "    accuracy                           0.84       267\n",
      "   macro avg       0.85      0.81      0.82       267\n",
      "weighted avg       0.85      0.84      0.84       267\n",
      "\n",
      "[[156  10]\n",
      " [ 32  69]]\n",
      "No. of Estimators: 19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88       166\n",
      "           1       0.87      0.68      0.77       101\n",
      "\n",
      "    accuracy                           0.84       267\n",
      "   macro avg       0.85      0.81      0.82       267\n",
      "weighted avg       0.85      0.84      0.84       267\n",
      "\n",
      "[[156  10]\n",
      " [ 32  69]]\n",
      "No. of Estimators: 20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88       166\n",
      "           1       0.87      0.68      0.77       101\n",
      "\n",
      "    accuracy                           0.84       267\n",
      "   macro avg       0.85      0.81      0.82       267\n",
      "weighted avg       0.85      0.84      0.84       267\n",
      "\n",
      "[[156  10]\n",
      " [ 32  69]]\n",
      "No. of Estimators: 21\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88       166\n",
      "           1       0.87      0.68      0.77       101\n",
      "\n",
      "    accuracy                           0.84       267\n",
      "   macro avg       0.85      0.81      0.82       267\n",
      "weighted avg       0.85      0.84      0.84       267\n",
      "\n",
      "[[156  10]\n",
      " [ 32  69]]\n",
      "No. of Estimators: 22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88       166\n",
      "           1       0.87      0.68      0.77       101\n",
      "\n",
      "    accuracy                           0.84       267\n",
      "   macro avg       0.85      0.81      0.82       267\n",
      "weighted avg       0.85      0.84      0.84       267\n",
      "\n",
      "[[156  10]\n",
      " [ 32  69]]\n",
      "No. of Estimators: 23\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88       166\n",
      "           1       0.87      0.68      0.77       101\n",
      "\n",
      "    accuracy                           0.84       267\n",
      "   macro avg       0.85      0.81      0.82       267\n",
      "weighted avg       0.85      0.84      0.84       267\n",
      "\n",
      "[[156  10]\n",
      " [ 32  69]]\n",
      "No. of Estimators: 24\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88       166\n",
      "           1       0.88      0.69      0.77       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.82      0.83       267\n",
      "weighted avg       0.85      0.85      0.84       267\n",
      "\n",
      "[[156  10]\n",
      " [ 31  70]]\n",
      "No. of Estimators: 25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89       166\n",
      "           1       0.88      0.70      0.78       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.86      0.82      0.83       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[156  10]\n",
      " [ 30  71]]\n",
      "No. of Estimators: 26\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89       166\n",
      "           1       0.88      0.70      0.78       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.86      0.82      0.83       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[156  10]\n",
      " [ 30  71]]\n",
      "No. of Estimators: 27\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89       166\n",
      "           1       0.88      0.70      0.78       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.86      0.82      0.83       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[156  10]\n",
      " [ 30  71]]\n",
      "No. of Estimators: 28\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89       166\n",
      "           1       0.89      0.70      0.78       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.86      0.82      0.84       267\n",
      "weighted avg       0.86      0.85      0.85       267\n",
      "\n",
      "[[157   9]\n",
      " [ 30  71]]\n",
      "No. of Estimators: 29\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89       166\n",
      "           1       0.89      0.70      0.78       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.86      0.82      0.84       267\n",
      "weighted avg       0.86      0.85      0.85       267\n",
      "\n",
      "[[157   9]\n",
      " [ 30  71]]\n",
      "No. of Estimators: 30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89       166\n",
      "           1       0.89      0.71      0.79       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.87      0.83      0.84       267\n",
      "weighted avg       0.86      0.86      0.85       267\n",
      "\n",
      "[[157   9]\n",
      " [ 29  72]]\n",
      "No. of Estimators: 31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89       166\n",
      "           1       0.89      0.70      0.78       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.86      0.82      0.84       267\n",
      "weighted avg       0.86      0.85      0.85       267\n",
      "\n",
      "[[157   9]\n",
      " [ 30  71]]\n",
      "No. of Estimators: 32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89       166\n",
      "           1       0.89      0.70      0.78       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.86      0.82      0.84       267\n",
      "weighted avg       0.86      0.85      0.85       267\n",
      "\n",
      "[[157   9]\n",
      " [ 30  71]]\n",
      "No. of Estimators: 33\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89       166\n",
      "           1       0.88      0.70      0.78       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.86      0.82      0.83       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[156  10]\n",
      " [ 30  71]]\n",
      "No. of Estimators: 34\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89       166\n",
      "           1       0.88      0.71      0.79       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.86      0.83      0.84       267\n",
      "weighted avg       0.86      0.85      0.85       267\n",
      "\n",
      "[[156  10]\n",
      " [ 29  72]]\n",
      "No. of Estimators: 35\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89       166\n",
      "           1       0.88      0.71      0.79       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.86      0.83      0.84       267\n",
      "weighted avg       0.86      0.85      0.85       267\n",
      "\n",
      "[[156  10]\n",
      " [ 29  72]]\n",
      "No. of Estimators: 36\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89       166\n",
      "           1       0.88      0.71      0.79       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.86      0.83      0.84       267\n",
      "weighted avg       0.86      0.85      0.85       267\n",
      "\n",
      "[[156  10]\n",
      " [ 29  72]]\n",
      "No. of Estimators: 37\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88       166\n",
      "           1       0.88      0.69      0.77       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.82      0.83       267\n",
      "weighted avg       0.85      0.85      0.84       267\n",
      "\n",
      "[[156  10]\n",
      " [ 31  70]]\n",
      "No. of Estimators: 38\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89       166\n",
      "           1       0.89      0.69      0.78       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.86      0.82      0.83       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[157   9]\n",
      " [ 31  70]]\n",
      "No. of Estimators: 39\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88       166\n",
      "           1       0.88      0.69      0.77       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.82      0.83       267\n",
      "weighted avg       0.85      0.85      0.84       267\n",
      "\n",
      "[[156  10]\n",
      " [ 31  70]]\n",
      "No. of Estimators: 40\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89       166\n",
      "           1       0.88      0.70      0.78       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.86      0.82      0.83       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[156  10]\n",
      " [ 30  71]]\n",
      "No. of Estimators: 41\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89       166\n",
      "           1       0.88      0.70      0.78       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.86      0.82      0.83       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[156  10]\n",
      " [ 30  71]]\n",
      "No. of Estimators: 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89       166\n",
      "           1       0.88      0.70      0.78       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.86      0.82      0.83       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[156  10]\n",
      " [ 30  71]]\n",
      "No. of Estimators: 43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.93      0.89       166\n",
      "           1       0.87      0.72      0.79       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.86      0.83      0.84       267\n",
      "weighted avg       0.86      0.85      0.85       267\n",
      "\n",
      "[[155  11]\n",
      " [ 28  73]]\n",
      "No. of Estimators: 44\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.93      0.89       166\n",
      "           1       0.87      0.72      0.79       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.86      0.83      0.84       267\n",
      "weighted avg       0.86      0.85      0.85       267\n",
      "\n",
      "[[155  11]\n",
      " [ 28  73]]\n",
      "No. of Estimators: 45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.88       166\n",
      "           1       0.87      0.70      0.78       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.82      0.83       267\n",
      "weighted avg       0.85      0.85      0.84       267\n",
      "\n",
      "[[155  11]\n",
      " [ 30  71]]\n",
      "No. of Estimators: 46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.88       166\n",
      "           1       0.86      0.71      0.78       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.82      0.83       267\n",
      "weighted avg       0.85      0.85      0.84       267\n",
      "\n",
      "[[154  12]\n",
      " [ 29  72]]\n",
      "No. of Estimators: 47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.88       166\n",
      "           1       0.86      0.71      0.78       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.82      0.83       267\n",
      "weighted avg       0.85      0.85      0.84       267\n",
      "\n",
      "[[154  12]\n",
      " [ 29  72]]\n",
      "No. of Estimators: 48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.88       166\n",
      "           1       0.86      0.71      0.78       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.82      0.83       267\n",
      "weighted avg       0.85      0.85      0.84       267\n",
      "\n",
      "[[154  12]\n",
      " [ 29  72]]\n",
      "No. of Estimators: 49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.92      0.88       166\n",
      "           1       0.85      0.71      0.77       101\n",
      "\n",
      "    accuracy                           0.84       267\n",
      "   macro avg       0.84      0.82      0.83       267\n",
      "weighted avg       0.84      0.84      0.84       267\n",
      "\n",
      "[[153  13]\n",
      " [ 29  72]]\n",
      "No. of Estimators: 50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.92      0.88       166\n",
      "           1       0.85      0.71      0.77       101\n",
      "\n",
      "    accuracy                           0.84       267\n",
      "   macro avg       0.84      0.82      0.83       267\n",
      "weighted avg       0.84      0.84      0.84       267\n",
      "\n",
      "[[153  13]\n",
      " [ 29  72]]\n",
      "No. of Estimators: 51\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.89       166\n",
      "           1       0.86      0.74      0.80       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.86      0.84      0.84       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[154  12]\n",
      " [ 26  75]]\n",
      "No. of Estimators: 52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.89       166\n",
      "           1       0.86      0.74      0.80       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.86      0.84      0.84       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[154  12]\n",
      " [ 26  75]]\n",
      "No. of Estimators: 53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.89       166\n",
      "           1       0.86      0.74      0.80       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.86      0.84      0.84       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[154  12]\n",
      " [ 26  75]]\n",
      "No. of Estimators: 54\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.89       166\n",
      "           1       0.85      0.74      0.79       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.83      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[153  13]\n",
      " [ 26  75]]\n",
      "No. of Estimators: 55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.89       166\n",
      "           1       0.85      0.74      0.79       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.83      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[153  13]\n",
      " [ 26  75]]\n",
      "No. of Estimators: 56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.89       166\n",
      "           1       0.85      0.74      0.79       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.83      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[153  13]\n",
      " [ 26  75]]\n",
      "No. of Estimators: 57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89       166\n",
      "           1       0.86      0.76      0.81       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.86      0.84      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[153  13]\n",
      " [ 24  77]]\n",
      "No. of Estimators: 58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89       166\n",
      "           1       0.86      0.76      0.81       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.86      0.84      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[153  13]\n",
      " [ 24  77]]\n",
      "No. of Estimators: 59\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89       166\n",
      "           1       0.86      0.76      0.81       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.86      0.84      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[153  13]\n",
      " [ 24  77]]\n",
      "No. of Estimators: 60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89       166\n",
      "           1       0.86      0.76      0.81       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.86      0.84      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[153  13]\n",
      " [ 24  77]]\n",
      "No. of Estimators: 61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89       166\n",
      "           1       0.86      0.76      0.81       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.86      0.84      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[153  13]\n",
      " [ 24  77]]\n",
      "No. of Estimators: 62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89       166\n",
      "           1       0.85      0.76      0.80       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.85      0.84      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[152  14]\n",
      " [ 24  77]]\n",
      "No. of Estimators: 63\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89       166\n",
      "           1       0.85      0.76      0.80       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.85      0.84      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[152  14]\n",
      " [ 24  77]]\n",
      "No. of Estimators: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89       166\n",
      "           1       0.86      0.76      0.81       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.86      0.84      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[153  13]\n",
      " [ 24  77]]\n",
      "No. of Estimators: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89       166\n",
      "           1       0.85      0.76      0.80       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.85      0.84      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[152  14]\n",
      " [ 24  77]]\n",
      "No. of Estimators: 66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89       166\n",
      "           1       0.85      0.76      0.80       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.85      0.84      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[152  14]\n",
      " [ 24  77]]\n",
      "No. of Estimators: 67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89       166\n",
      "           1       0.85      0.76      0.80       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.85      0.84      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[152  14]\n",
      " [ 24  77]]\n",
      "No. of Estimators: 68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89       166\n",
      "           1       0.85      0.76      0.80       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.85      0.84      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[152  14]\n",
      " [ 24  77]]\n",
      "No. of Estimators: 69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89       166\n",
      "           1       0.85      0.76      0.80       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.85      0.84      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[152  14]\n",
      " [ 24  77]]\n",
      "No. of Estimators: 70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89       166\n",
      "           1       0.85      0.76      0.80       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.85      0.84      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[152  14]\n",
      " [ 24  77]]\n",
      "No. of Estimators: 71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89       166\n",
      "           1       0.85      0.76      0.80       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.85      0.84      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[152  14]\n",
      " [ 24  77]]\n",
      "No. of Estimators: 72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89       166\n",
      "           1       0.85      0.76      0.80       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.85      0.84      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[152  14]\n",
      " [ 24  77]]\n",
      "No. of Estimators: 73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89       166\n",
      "           1       0.85      0.76      0.80       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.85      0.84      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[152  14]\n",
      " [ 24  77]]\n",
      "No. of Estimators: 74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89       166\n",
      "           1       0.85      0.76      0.80       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.85      0.84      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[152  14]\n",
      " [ 24  77]]\n",
      "No. of Estimators: 75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.89       166\n",
      "           1       0.84      0.76      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[151  15]\n",
      " [ 24  77]]\n",
      "No. of Estimators: 76\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.89       166\n",
      "           1       0.84      0.76      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[151  15]\n",
      " [ 24  77]]\n",
      "No. of Estimators: 77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89       166\n",
      "           1       0.86      0.76      0.81       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.86      0.84      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[153  13]\n",
      " [ 24  77]]\n",
      "No. of Estimators: 78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89       166\n",
      "           1       0.86      0.76      0.81       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.86      0.84      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[153  13]\n",
      " [ 24  77]]\n",
      "No. of Estimators: 79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89       166\n",
      "           1       0.85      0.76      0.80       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.85      0.84      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[152  14]\n",
      " [ 24  77]]\n",
      "No. of Estimators: 80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89       166\n",
      "           1       0.84      0.75      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.83      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[152  14]\n",
      " [ 25  76]]\n",
      "No. of Estimators: 81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89       166\n",
      "           1       0.84      0.75      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.83      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[152  14]\n",
      " [ 25  76]]\n",
      "No. of Estimators: 82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.88       166\n",
      "           1       0.84      0.75      0.79       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.83      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[151  15]\n",
      " [ 25  76]]\n",
      "No. of Estimators: 83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89       166\n",
      "           1       0.84      0.75      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.83      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[152  14]\n",
      " [ 25  76]]\n",
      "No. of Estimators: 84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89       166\n",
      "           1       0.85      0.75      0.80       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.86      0.84      0.84       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[153  13]\n",
      " [ 25  76]]\n",
      "No. of Estimators: 85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89       166\n",
      "           1       0.84      0.75      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.83      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[152  14]\n",
      " [ 25  76]]\n",
      "No. of Estimators: 86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89       166\n",
      "           1       0.84      0.77      0.80       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.85      0.84      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[151  15]\n",
      " [ 23  78]]\n",
      "No. of Estimators: 87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.89       166\n",
      "           1       0.84      0.76      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[151  15]\n",
      " [ 24  77]]\n",
      "No. of Estimators: 88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.89       166\n",
      "           1       0.84      0.76      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[151  15]\n",
      " [ 24  77]]\n",
      "No. of Estimators: 89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89       166\n",
      "           1       0.84      0.77      0.80       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.85      0.84      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[151  15]\n",
      " [ 23  78]]\n",
      "No. of Estimators: 90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89       166\n",
      "           1       0.84      0.77      0.80       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.85      0.84      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[151  15]\n",
      " [ 23  78]]\n",
      "No. of Estimators: 91\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89       166\n",
      "           1       0.86      0.77      0.81       101\n",
      "\n",
      "    accuracy                           0.87       267\n",
      "   macro avg       0.86      0.85      0.85       267\n",
      "weighted avg       0.86      0.87      0.86       267\n",
      "\n",
      "[[153  13]\n",
      " [ 23  78]]\n",
      "No. of Estimators: 92\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89       166\n",
      "           1       0.85      0.77      0.81       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.86      0.84      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[152  14]\n",
      " [ 23  78]]\n",
      "No. of Estimators: 93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89       166\n",
      "           1       0.85      0.77      0.81       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.86      0.84      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[152  14]\n",
      " [ 23  78]]\n",
      "No. of Estimators: 94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89       166\n",
      "           1       0.85      0.77      0.81       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.86      0.84      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[152  14]\n",
      " [ 23  78]]\n",
      "No. of Estimators: 95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89       166\n",
      "           1       0.85      0.77      0.81       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.86      0.84      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[152  14]\n",
      " [ 23  78]]\n",
      "No. of Estimators: 96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89       166\n",
      "           1       0.84      0.77      0.80       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.85      0.84      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[151  15]\n",
      " [ 23  78]]\n",
      "No. of Estimators: 97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89       166\n",
      "           1       0.84      0.77      0.80       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.85      0.84      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[151  15]\n",
      " [ 23  78]]\n",
      "No. of Estimators: 98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89       166\n",
      "           1       0.85      0.77      0.81       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.86      0.84      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[152  14]\n",
      " [ 23  78]]\n",
      "No. of Estimators: 99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89       166\n",
      "           1       0.85      0.77      0.81       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.86      0.84      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[152  14]\n",
      " [ 23  78]]\n",
      "No. of Estimators: 100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89       166\n",
      "           1       0.85      0.77      0.81       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.86      0.84      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[152  14]\n",
      " [ 23  78]]\n"
     ]
    }
   ],
   "source": [
    "#create an object for GradientBoostingClassifier class\n",
    "#and passing the parameter n_estimator means how many iteration \n",
    "#means how many Decision Tree use for train the model , n_estimators should be >=10 and <=100\n",
    "#create for loop for estimators\n",
    "for i in range(10,101):\n",
    "    gbc = GradientBoostingClassifier(n_estimators=i,random_state=1)\n",
    "    print(\"No. of Estimators:\",i)\n",
    "    #call function\n",
    "    gbc = create_model(gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "470ec249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89       166\n",
      "           1       0.86      0.76      0.81       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.86      0.84      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[153  13]\n",
      " [ 24  77]]\n"
     ]
    }
   ],
   "source": [
    "#Got the good score at 57\n",
    "gbc = GradientBoostingClassifier(n_estimators=57,random_state=1)\n",
    "#call function\n",
    "gbc = create_model(gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0a85fade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>IG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sex</td>\n",
       "      <td>0.405181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pclass</td>\n",
       "      <td>0.122289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ticket</td>\n",
       "      <td>0.117819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.104657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fare</td>\n",
       "      <td>0.079008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Name</td>\n",
       "      <td>0.075906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SibSp</td>\n",
       "      <td>0.046192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PassengerId</td>\n",
       "      <td>0.027899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Embarked</td>\n",
       "      <td>0.018902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Parch</td>\n",
       "      <td>0.002148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Input        IG\n",
       "0          Sex  0.405181\n",
       "1       Pclass  0.122289\n",
       "2       Ticket  0.117819\n",
       "3          Age  0.104657\n",
       "4         Fare  0.079008\n",
       "5         Name  0.075906\n",
       "6        SibSp  0.046192\n",
       "7  PassengerId  0.027899\n",
       "8     Embarked  0.018902\n",
       "9        Parch  0.002148"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now check information gain(IG)\n",
    "dict11 = {\"Input\":x.columns,\"IG\":gbc.feature_importances_}\n",
    "df12 = pd.DataFrame(dict11)\n",
    "df12.sort_values(\"IG\",ascending=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4094b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#While applyiyng GradientBoostingClassifier we got recall score 76% which is good but not better\n",
    "#So we apply 3rd boosting technique :Extreme Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c4e8ab7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.ExtremeGradientBossting (XGB):- it is better version of Gradient Technique\n",
    "#call inbuilt class XGBClassifier from xgboost packgae\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ff419908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of estimators: 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.87       166\n",
      "           1       0.82      0.73      0.77       101\n",
      "\n",
      "    accuracy                           0.84       267\n",
      "   macro avg       0.83      0.82      0.82       267\n",
      "weighted avg       0.84      0.84      0.84       267\n",
      "\n",
      "[[150  16]\n",
      " [ 27  74]]\n",
      "No. of estimators: 11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88       166\n",
      "           1       0.83      0.73      0.78       101\n",
      "\n",
      "    accuracy                           0.84       267\n",
      "   macro avg       0.84      0.82      0.83       267\n",
      "weighted avg       0.84      0.84      0.84       267\n",
      "\n",
      "[[151  15]\n",
      " [ 27  74]]\n",
      "No. of estimators: 12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.87       166\n",
      "           1       0.82      0.73      0.77       101\n",
      "\n",
      "    accuracy                           0.84       267\n",
      "   macro avg       0.83      0.82      0.82       267\n",
      "weighted avg       0.84      0.84      0.84       267\n",
      "\n",
      "[[150  16]\n",
      " [ 27  74]]\n",
      "No. of estimators: 13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.87       166\n",
      "           1       0.81      0.75      0.78       101\n",
      "\n",
      "    accuracy                           0.84       267\n",
      "   macro avg       0.83      0.82      0.83       267\n",
      "weighted avg       0.84      0.84      0.84       267\n",
      "\n",
      "[[148  18]\n",
      " [ 25  76]]\n",
      "No. of estimators: 14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87       166\n",
      "           1       0.81      0.74      0.77       101\n",
      "\n",
      "    accuracy                           0.84       267\n",
      "   macro avg       0.83      0.82      0.82       267\n",
      "weighted avg       0.83      0.84      0.83       267\n",
      "\n",
      "[[148  18]\n",
      " [ 26  75]]\n",
      "No. of estimators: 15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.90      0.87       166\n",
      "           1       0.81      0.72      0.76       101\n",
      "\n",
      "    accuracy                           0.83       267\n",
      "   macro avg       0.83      0.81      0.82       267\n",
      "weighted avg       0.83      0.83      0.83       267\n",
      "\n",
      "[[149  17]\n",
      " [ 28  73]]\n",
      "No. of estimators: 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.87       166\n",
      "           1       0.82      0.73      0.77       101\n",
      "\n",
      "    accuracy                           0.84       267\n",
      "   macro avg       0.83      0.82      0.82       267\n",
      "weighted avg       0.84      0.84      0.84       267\n",
      "\n",
      "[[150  16]\n",
      " [ 27  74]]\n",
      "No. of estimators: 17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.88       166\n",
      "           1       0.82      0.74      0.78       101\n",
      "\n",
      "    accuracy                           0.84       267\n",
      "   macro avg       0.84      0.82      0.83       267\n",
      "weighted avg       0.84      0.84      0.84       267\n",
      "\n",
      "[[150  16]\n",
      " [ 26  75]]\n",
      "No. of estimators: 18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.88       166\n",
      "           1       0.82      0.77      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.84      0.83      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[149  17]\n",
      " [ 23  78]]\n",
      "No. of estimators: 19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.88       166\n",
      "           1       0.81      0.76      0.79       101\n",
      "\n",
      "    accuracy                           0.84       267\n",
      "   macro avg       0.84      0.83      0.83       267\n",
      "weighted avg       0.84      0.84      0.84       267\n",
      "\n",
      "[[148  18]\n",
      " [ 24  77]]\n",
      "No. of estimators: 20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.88       166\n",
      "           1       0.81      0.76      0.79       101\n",
      "\n",
      "    accuracy                           0.84       267\n",
      "   macro avg       0.84      0.83      0.83       267\n",
      "weighted avg       0.84      0.84      0.84       267\n",
      "\n",
      "[[148  18]\n",
      " [ 24  77]]\n",
      "No. of estimators: 21\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88       166\n",
      "           1       0.81      0.77      0.79       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.84      0.83      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 23  78]]\n",
      "No. of estimators: 22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88       166\n",
      "           1       0.82      0.76      0.79       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.84      0.83      0.83       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[149  17]\n",
      " [ 24  77]]\n",
      "No. of estimators: 23\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88       166\n",
      "           1       0.82      0.76      0.79       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.84      0.83      0.83       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[149  17]\n",
      " [ 24  77]]\n",
      "No. of estimators: 24\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.88       166\n",
      "           1       0.82      0.77      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.84      0.83      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[149  17]\n",
      " [ 23  78]]\n",
      "No. of estimators: 25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88       166\n",
      "           1       0.81      0.78      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.84      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 22  79]]\n",
      "No. of estimators: 26\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88       166\n",
      "           1       0.81      0.78      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.84      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 22  79]]\n",
      "No. of estimators: 27\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89       166\n",
      "           1       0.82      0.79      0.81       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.85      0.84      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[149  17]\n",
      " [ 21  80]]\n",
      "No. of estimators: 28\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89       166\n",
      "           1       0.82      0.79      0.81       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.85      0.84      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[149  17]\n",
      " [ 21  80]]\n",
      "No. of estimators: 29\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89       166\n",
      "           1       0.82      0.79      0.81       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.85      0.84      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[149  17]\n",
      " [ 21  80]]\n",
      "No. of estimators: 30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89       166\n",
      "           1       0.83      0.79      0.81       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.86      0.85      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[150  16]\n",
      " [ 21  80]]\n",
      "No. of estimators: 31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89       166\n",
      "           1       0.82      0.79      0.81       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.85      0.84      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[149  17]\n",
      " [ 21  80]]\n",
      "No. of estimators: 32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89       166\n",
      "           1       0.82      0.79      0.81       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.85      0.84      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[149  17]\n",
      " [ 21  80]]\n",
      "No. of estimators: 33\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89       166\n",
      "           1       0.82      0.79      0.81       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.85      0.84      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[149  17]\n",
      " [ 21  80]]\n",
      "No. of estimators: 34\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89       166\n",
      "           1       0.82      0.81      0.82       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.85      0.85      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[148  18]\n",
      " [ 19  82]]\n",
      "No. of estimators: 35\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89       166\n",
      "           1       0.82      0.82      0.82       101\n",
      "\n",
      "    accuracy                           0.87       267\n",
      "   macro avg       0.86      0.86      0.86       267\n",
      "weighted avg       0.87      0.87      0.87       267\n",
      "\n",
      "[[148  18]\n",
      " [ 18  83]]\n",
      "No. of estimators: 36\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       166\n",
      "           1       0.82      0.79      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 21  80]]\n",
      "No. of estimators: 37\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.89       166\n",
      "           1       0.82      0.80      0.81       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.85      0.85      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[148  18]\n",
      " [ 20  81]]\n",
      "No. of estimators: 38\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89       166\n",
      "           1       0.82      0.81      0.82       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.85      0.85      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[148  18]\n",
      " [ 19  82]]\n",
      "No. of estimators: 39\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89       166\n",
      "           1       0.82      0.81      0.82       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.85      0.85      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[148  18]\n",
      " [ 19  82]]\n",
      "No. of estimators: 40\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.89       166\n",
      "           1       0.82      0.80      0.81       101\n",
      "\n",
      "    accuracy                           0.86       267\n",
      "   macro avg       0.85      0.85      0.85       267\n",
      "weighted avg       0.86      0.86      0.86       267\n",
      "\n",
      "[[148  18]\n",
      " [ 20  81]]\n",
      "No. of estimators: 41\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       166\n",
      "           1       0.82      0.79      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 21  80]]\n",
      "No. of estimators: 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       166\n",
      "           1       0.82      0.79      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 21  80]]\n",
      "No. of estimators: 43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88       166\n",
      "           1       0.81      0.78      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.84      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 22  79]]\n",
      "No. of estimators: 44\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88       166\n",
      "           1       0.81      0.78      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.84      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 22  79]]\n",
      "No. of estimators: 45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88       166\n",
      "           1       0.81      0.78      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.84      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 22  79]]\n",
      "No. of estimators: 46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       166\n",
      "           1       0.82      0.79      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 21  80]]\n",
      "No. of estimators: 47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       166\n",
      "           1       0.82      0.79      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 21  80]]\n",
      "No. of estimators: 48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       166\n",
      "           1       0.82      0.79      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 21  80]]\n",
      "No. of estimators: 49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       166\n",
      "           1       0.82      0.79      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 21  80]]\n",
      "No. of estimators: 50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       166\n",
      "           1       0.82      0.79      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 21  80]]\n",
      "No. of estimators: 51\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       166\n",
      "           1       0.82      0.79      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 21  80]]\n",
      "No. of estimators: 52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       166\n",
      "           1       0.82      0.79      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 21  80]]\n",
      "No. of estimators: 53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       166\n",
      "           1       0.82      0.79      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 21  80]]\n",
      "No. of estimators: 54\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       166\n",
      "           1       0.82      0.79      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 21  80]]\n",
      "No. of estimators: 55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       166\n",
      "           1       0.82      0.79      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 21  80]]\n",
      "No. of estimators: 56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       166\n",
      "           1       0.82      0.79      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 21  80]]\n",
      "No. of estimators: 57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       166\n",
      "           1       0.82      0.79      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 21  80]]\n",
      "No. of estimators: 58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       166\n",
      "           1       0.82      0.79      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 21  80]]\n",
      "No. of estimators: 59\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       166\n",
      "           1       0.82      0.79      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 21  80]]\n",
      "No. of estimators: 60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       166\n",
      "           1       0.82      0.79      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 21  80]]\n",
      "No. of estimators: 61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       166\n",
      "           1       0.82      0.79      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 21  80]]\n",
      "No. of estimators: 62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       166\n",
      "           1       0.82      0.79      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 21  80]]\n",
      "No. of estimators: 63\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       166\n",
      "           1       0.82      0.79      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 21  80]]\n",
      "No. of estimators: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       166\n",
      "           1       0.82      0.79      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 21  80]]\n",
      "No. of estimators: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       166\n",
      "           1       0.82      0.79      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 21  80]]\n",
      "No. of estimators: 66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       166\n",
      "           1       0.82      0.79      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 21  80]]\n",
      "No. of estimators: 67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       166\n",
      "           1       0.82      0.79      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 21  80]]\n",
      "No. of estimators: 68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       166\n",
      "           1       0.82      0.79      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 21  80]]\n",
      "No. of estimators: 69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       166\n",
      "           1       0.82      0.79      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 21  80]]\n",
      "No. of estimators: 70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       166\n",
      "           1       0.82      0.79      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 21  80]]\n",
      "No. of estimators: 71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       166\n",
      "           1       0.82      0.79      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 21  80]]\n",
      "No. of estimators: 72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       166\n",
      "           1       0.82      0.79      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 21  80]]\n",
      "No. of estimators: 73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       166\n",
      "           1       0.82      0.79      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 21  80]]\n",
      "No. of estimators: 74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       166\n",
      "           1       0.82      0.79      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 21  80]]\n",
      "No. of estimators: 75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       166\n",
      "           1       0.82      0.79      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 21  80]]\n",
      "No. of estimators: 76\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       166\n",
      "           1       0.82      0.79      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 21  80]]\n",
      "No. of estimators: 77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       166\n",
      "           1       0.82      0.79      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 21  80]]\n",
      "No. of estimators: 78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       166\n",
      "           1       0.82      0.79      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 21  80]]\n",
      "No. of estimators: 79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       166\n",
      "           1       0.82      0.79      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 21  80]]\n",
      "No. of estimators: 80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       166\n",
      "           1       0.82      0.79      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 21  80]]\n",
      "No. of estimators: 81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       166\n",
      "           1       0.82      0.79      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 21  80]]\n",
      "No. of estimators: 82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       166\n",
      "           1       0.82      0.79      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 21  80]]\n",
      "No. of estimators: 83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       166\n",
      "           1       0.82      0.79      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 21  80]]\n",
      "No. of estimators: 84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       166\n",
      "           1       0.82      0.79      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 21  80]]\n",
      "No. of estimators: 85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       166\n",
      "           1       0.82      0.79      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 21  80]]\n",
      "No. of estimators: 86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       166\n",
      "           1       0.82      0.79      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 21  80]]\n",
      "No. of estimators: 87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       166\n",
      "           1       0.82      0.79      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 21  80]]\n",
      "No. of estimators: 88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       166\n",
      "           1       0.82      0.79      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 21  80]]\n",
      "No. of estimators: 89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       166\n",
      "           1       0.82      0.79      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 21  80]]\n",
      "No. of estimators: 90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       166\n",
      "           1       0.82      0.79      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 21  80]]\n",
      "No. of estimators: 91\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       166\n",
      "           1       0.82      0.79      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 21  80]]\n",
      "No. of estimators: 92\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       166\n",
      "           1       0.82      0.79      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 21  80]]\n",
      "No. of estimators: 93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       166\n",
      "           1       0.82      0.79      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 21  80]]\n",
      "No. of estimators: 94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       166\n",
      "           1       0.82      0.79      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 21  80]]\n",
      "No. of estimators: 95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       166\n",
      "           1       0.82      0.79      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 21  80]]\n",
      "No. of estimators: 96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       166\n",
      "           1       0.82      0.79      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 21  80]]\n",
      "No. of estimators: 97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       166\n",
      "           1       0.82      0.79      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 21  80]]\n",
      "No. of estimators: 98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       166\n",
      "           1       0.82      0.79      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 21  80]]\n",
      "No. of estimators: 99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       166\n",
      "           1       0.82      0.79      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 21  80]]\n",
      "No. of estimators: 100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       166\n",
      "           1       0.82      0.79      0.80       101\n",
      "\n",
      "    accuracy                           0.85       267\n",
      "   macro avg       0.85      0.84      0.84       267\n",
      "weighted avg       0.85      0.85      0.85       267\n",
      "\n",
      "[[148  18]\n",
      " [ 21  80]]\n"
     ]
    }
   ],
   "source": [
    "#create function for XGBClassifier class\n",
    "#and passing the parameter n_estimators which is >=10 and <=100\n",
    "#create for-loop \n",
    "for i in range(10,101):\n",
    "    xgc = XGBClassifier(n_estimators=i,reg_alpha=1,random_state=1)\n",
    "    print(\"No. of estimators:\",i)\n",
    "    #call the function\n",
    "    xgc = create_model(xgc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7455bf93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89       166\n",
      "           1       0.82      0.82      0.82       101\n",
      "\n",
      "    accuracy                           0.87       267\n",
      "   macro avg       0.86      0.86      0.86       267\n",
      "weighted avg       0.87      0.87      0.87       267\n",
      "\n",
      "[[148  18]\n",
      " [ 18  83]]\n"
     ]
    }
   ],
   "source": [
    "#We got better score at 35\n",
    "xgc = XGBClassifier(n_estimators=35,reg_alpha=1,random_state=1)\n",
    "#call the function\n",
    "xgc = create_model(xgc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0626a639",
   "metadata": {},
   "outputs": [],
   "source": [
    "#While Applying Alorithms we got the better score of 83% in DecisionTreeClassifier W"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
